{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "# K-Scale Humanoid Benchmark\n",
        "\n",
        "Welcome to the K-Scale Humanoid Benchmark! This notebook will walk you through training your own reinforcement learning policy, which you can then use to control a K-Scale robot."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GcUyV2BhHCxS",
      "metadata": {
        "id": "GcUyV2BhHCxS"
      },
      "source": [
        "## Dependencies and Config\n",
        "\n",
        "The K-Scale Humanoid Benchmark uses K-Scale's open-source RL framework [K-Sim](https://github.com/kscalelabs/ksim) for training and the [K-Scale API](https://github.com/kscalelabs/kscale) for asset management.\n",
        "\n",
        "To get your API key, install the K-Scale CLI with `pip install kscale` and run `ks user key` in your terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "X9GR-PWjgynB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9GR-PWjgynB",
        "outputId": "8b5227f7-e06e-465e-ce65-ed19f75d1191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/99.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.3/709.3 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ksim (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.3/170.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.7/91.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.2/182.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for kos-sim (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kmv (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for evdev (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Found existing installation: xax 0.2.18\n",
            "Uninstalling xax-0.2.18:\n",
            "  Successfully uninstalled xax-0.2.18\n",
            "Collecting git+https://github.com/kscalelabs/xax.git@fix-for-notebook\n",
            "  Cloning https://github.com/kscalelabs/xax.git (to revision fix-for-notebook) to /tmp/pip-req-build-3i9766h4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/kscalelabs/xax.git /tmp/pip-req-build-3i9766h4\n",
            "  Running command git checkout -b fix-for-notebook --track origin/fix-for-notebook\n",
            "  Switched to a new branch 'fix-for-notebook'\n",
            "  Branch 'fix-for-notebook' set up to track remote branch 'fix-for-notebook' from 'origin'.\n",
            "  Resolved https://github.com/kscalelabs/xax.git to commit e55188976cfad33ac26f49b49b949207c804bc5a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (25.3.0)\n",
            "Requirement already satisfied: chex in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (0.1.89)\n",
            "Requirement already satisfied: dpshdl in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (0.0.21)\n",
            "Requirement already satisfied: equinox in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (0.12.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (6.5.2)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (0.5.2)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (0.3.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (0.2.4)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (0.11.12)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (11.2.1)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (2.3.0)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (3.1.44)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (2.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (5.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from xax==0.2.18) (2.32.3)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex->xax==0.2.18) (1.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from chex->xax==0.2.18) (4.13.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from chex->xax==0.2.18) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.11/dist-packages (from chex->xax==0.2.18) (2.0.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex->xax==0.2.18) (0.12.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->xax==0.2.18) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->xax==0.2.18) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->xax==0.2.18) (1.15.2)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from equinox->xax==0.2.18) (0.1.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->xax==0.2.18) (4.0.12)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->xax==0.2.18) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf->xax==0.2.18) (6.0.2)\n",
            "Requirement already satisfied: etils[epy] in /usr/local/lib/python3.11/dist-packages (from optax->xax==0.2.18) (1.12.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->xax==0.2.18) (1.1.0)\n",
            "Requirement already satisfied: tensorstore>=0.1.71 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->xax==0.2.18) (0.1.74)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->xax==0.2.18) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->xax==0.2.18) (5.29.4)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->xax==0.2.18) (4.12.2)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint->xax==0.2.18) (3.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->xax==0.2.18) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->xax==0.2.18) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->xax==0.2.18) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->xax==0.2.18) (2025.4.26)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->xax==0.2.18) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->xax==0.2.18) (3.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard->xax==0.2.18) (24.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->xax==0.2.18) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->xax==0.2.18) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->xax==0.2.18) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->xax==0.2.18) (3.1.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->xax==0.2.18) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->xax==0.2.18) (3.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->xax==0.2.18) (2025.3.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint->xax==0.2.18) (3.21.0)\n",
            "Building wheels for collected packages: xax\n",
            "  Building wheel for xax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xax: filename=xax-0.2.18-py3-none-any.whl size=104482 sha256=bfd780a8d44df712dab5b47c87e87e427345a4e0d42b3fe1434de26eec70e813\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vuc_2po5/wheels/39/9f/74/cf89d2d94df51ee9a8918890369a0aaa3e16275b9f27d7e7e5\n",
            "Successfully built xax\n",
            "Installing collected packages: xax\n",
            "Successfully installed xax-0.2.18\n"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "\n",
        "!pip install -q ksim\n",
        "!pip install -q kos-sim\n",
        "!pip uninstall -y xax\n",
        "!pip install git+https://github.com/kscalelabs/xax.git@fix-for-notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "19e07786",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19e07786",
        "outputId": "78e173ed-afd3-45fc-a518-2a4a2ba31b8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TENSORBOARD_PORT=6036\n",
            "env: MUJOCO_GL=egl\n"
          ]
        }
      ],
      "source": [
        "# Set up environment variables\n",
        "import os\n",
        "from google.colab import userdata\n",
        "%env TENSORBOARD_PORT=6036\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "\n",
        "os.environ[\"KSCALE_API_KEY\"] = userdata.get('kscale-api-key')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1",
      "metadata": {
        "id": "1"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import Self\n",
        "\n",
        "import attrs\n",
        "import distrax\n",
        "import equinox as eqx\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import ksim\n",
        "import mujoco\n",
        "import mujoco_scenes\n",
        "import mujoco_scenes.mjcf\n",
        "import optax\n",
        "import xax\n",
        "from jaxtyping import Array, PRNGKeyArray\n",
        "from kscale.web.gen.api import JointMetadataOutput\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "outputs": [],
      "source": [
        "NUM_JOINTS = 20\n",
        "NUM_ACTOR_INPUTS = 43\n",
        "NUM_CRITIC_INPUTS = 444\n",
        "\n",
        "# These are in the order of the neural network outputs.\n",
        "ZEROS: list[tuple[str, float]] = [\n",
        "    (\"dof_right_shoulder_pitch_03\", 0.0),\n",
        "    (\"dof_right_shoulder_roll_03\", math.radians(-10.0)),\n",
        "    (\"dof_right_shoulder_yaw_02\", 0.0),\n",
        "    (\"dof_right_elbow_02\", math.radians(90.0)),\n",
        "    (\"dof_right_wrist_00\", 0.0),\n",
        "    (\"dof_left_shoulder_pitch_03\", 0.0),\n",
        "    (\"dof_left_shoulder_roll_03\", math.radians(10.0)),\n",
        "    (\"dof_left_shoulder_yaw_02\", 0.0),\n",
        "    (\"dof_left_elbow_02\", math.radians(-90.0)),\n",
        "    (\"dof_left_wrist_00\", 0.0),\n",
        "    (\"dof_right_hip_pitch_04\", math.radians(-25.0)),\n",
        "    (\"dof_right_hip_roll_03\", 0.0),\n",
        "    (\"dof_right_hip_yaw_03\", 0.0),\n",
        "    (\"dof_right_knee_04\", math.radians(-50.0)),\n",
        "    (\"dof_right_ankle_02\", math.radians(25.0)),\n",
        "    (\"dof_left_hip_pitch_04\", math.radians(25.0)),\n",
        "    (\"dof_left_hip_roll_03\", 0.0),\n",
        "    (\"dof_left_hip_yaw_03\", 0.0),\n",
        "    (\"dof_left_knee_04\", math.radians(50.0)),\n",
        "    (\"dof_left_ankle_02\", math.radians(-25.0)),\n",
        "]\n",
        "\n",
        "# These are the torques we clip outputs to when deploying the policy.\n",
        "MAX_TORQUE = {\n",
        "    \"00\": 1.0,  # 00 motor\n",
        "    \"02\": 13.0,  # 02 motor\n",
        "    \"03\": 48.0,  # 03 motor\n",
        "    \"04\": 96.0,  # 04 motor\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3",
      "metadata": {
        "id": "3"
      },
      "source": [
        "## Rewards\n",
        "\n",
        "When training a reinforcement learning agent, the most important thing to define is what reward you want the agent to maximimze. `ksim` includes a number of useful default rewards for training walking agents, but it is often a good idea to define new rewards to encourage specific types of behavior. The cell below shows an example of how to define a custom reward. A similar pattern can be used to define custom objectives, events, observations, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "outputs": [],
      "source": [
        "@attrs.define\n",
        "class BentArmPenalty(ksim.Reward):\n",
        "    arm_indices: tuple[int, ...] = attrs.field()\n",
        "    arm_targets: tuple[float, ...] = attrs.field()\n",
        "\n",
        "    def get_reward(self, trajectory: ksim.Trajectory) -> Array:\n",
        "        qpos = trajectory.qpos[..., self.arm_indices]\n",
        "        qpos_targets = jnp.array(self.arm_targets)\n",
        "        qpos_diff = qpos - qpos_targets\n",
        "        return xax.get_norm(qpos_diff, \"l1\").mean(axis=-1)\n",
        "\n",
        "    @classmethod\n",
        "    def create(\n",
        "        cls,\n",
        "        model: ksim.PhysicsModel,\n",
        "        scale: float,\n",
        "        scale_by_curriculum: bool = False,\n",
        "    ) -> Self:\n",
        "        qpos_mapping = ksim.get_qpos_data_idxs_by_name(model)\n",
        "\n",
        "        names = [\n",
        "            \"dof_right_shoulder_pitch_03\",\n",
        "            \"dof_right_shoulder_roll_03\",\n",
        "            \"dof_right_shoulder_yaw_02\",\n",
        "            \"dof_right_elbow_02\",\n",
        "            \"dof_right_wrist_00\",\n",
        "            \"dof_left_shoulder_pitch_03\",\n",
        "            \"dof_left_shoulder_roll_03\",\n",
        "            \"dof_left_shoulder_yaw_02\",\n",
        "            \"dof_left_elbow_02\",\n",
        "            \"dof_left_wrist_00\",\n",
        "        ]\n",
        "\n",
        "        zeros = {k: v for k, v in ZEROS}\n",
        "        arm_indices = [qpos_mapping[name][0] for name in names]\n",
        "        arm_targets = [zeros[name] for name in names]\n",
        "\n",
        "        return cls(\n",
        "            arm_indices=tuple(arm_indices),\n",
        "            arm_targets=tuple(arm_targets),\n",
        "            scale=scale,\n",
        "            scale_by_curriculum=scale_by_curriculum,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "source": [
        "## Actor-Critic Model\n",
        "\n",
        "We train our reinforcement learning agent using an RNN-based actor and critic, which we define below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "class Actor(eqx.Module):\n",
        "    \"\"\"Actor for the walking task.\"\"\"\n",
        "\n",
        "    input_proj: eqx.nn.Linear\n",
        "    rnns: tuple[eqx.nn.GRUCell, ...]\n",
        "    output_proj: eqx.nn.Linear\n",
        "    num_inputs: int = eqx.static_field()\n",
        "    num_outputs: int = eqx.static_field()\n",
        "    num_mixtures: int = eqx.static_field()\n",
        "    min_std: float = eqx.static_field()\n",
        "    max_std: float = eqx.static_field()\n",
        "    var_scale: float = eqx.static_field()\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        key: PRNGKeyArray,\n",
        "        *,\n",
        "        num_inputs: int,\n",
        "        num_outputs: int,\n",
        "        min_std: float,\n",
        "        max_std: float,\n",
        "        var_scale: float,\n",
        "        hidden_size: int,\n",
        "        num_mixtures: int,\n",
        "        depth: int,\n",
        "    ) -> None:\n",
        "        # Project input to hidden size\n",
        "        key, input_proj_key = jax.random.split(key)\n",
        "        self.input_proj = eqx.nn.Linear(\n",
        "            in_features=num_inputs,\n",
        "            out_features=hidden_size,\n",
        "            key=input_proj_key,\n",
        "        )\n",
        "\n",
        "        # Create RNN layer\n",
        "        key, rnn_key = jax.random.split(key)\n",
        "        self.rnns = tuple(\n",
        "            [\n",
        "                eqx.nn.GRUCell(\n",
        "                    input_size=hidden_size,\n",
        "                    hidden_size=hidden_size,\n",
        "                    key=rnn_key,\n",
        "                )\n",
        "                for _ in range(depth)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Project to output\n",
        "        self.output_proj = eqx.nn.Linear(\n",
        "            in_features=hidden_size,\n",
        "            out_features=num_outputs * 3 * num_mixtures,\n",
        "            key=key,\n",
        "        )\n",
        "\n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_outputs = num_outputs\n",
        "        self.num_mixtures = num_mixtures\n",
        "        self.min_std = min_std\n",
        "        self.max_std = max_std\n",
        "        self.var_scale = var_scale\n",
        "\n",
        "    def forward(self, obs_n: Array, carry: Array) -> tuple[distrax.Distribution, Array]:\n",
        "        x_n = self.input_proj(obs_n)\n",
        "        out_carries = []\n",
        "        for i, rnn in enumerate(self.rnns):\n",
        "            x_n = rnn(x_n, carry[i])\n",
        "            out_carries.append(x_n)\n",
        "        out_n = self.output_proj(x_n)\n",
        "\n",
        "        # Reshape the output to be a mixture of gaussians.\n",
        "        slice_len = NUM_JOINTS * self.num_mixtures\n",
        "        mean_nm = out_n[..., :slice_len].reshape(NUM_JOINTS, self.num_mixtures)\n",
        "        std_nm = out_n[..., slice_len : slice_len * 2].reshape(NUM_JOINTS, self.num_mixtures)\n",
        "        logits_nm = out_n[..., slice_len * 2 :].reshape(NUM_JOINTS, self.num_mixtures)\n",
        "\n",
        "        # Softplus and clip to ensure positive standard deviations.\n",
        "        std_nm = jnp.clip((jax.nn.softplus(std_nm) + self.min_std) * self.var_scale, max=self.max_std)\n",
        "\n",
        "        # Apply bias to the means.\n",
        "        mean_nm = mean_nm + jnp.array([v for _, v in ZEROS])[:, None]\n",
        "\n",
        "        dist_n = ksim.MixtureOfGaussians(means_nm=mean_nm, stds_nm=std_nm, logits_nm=logits_nm)\n",
        "\n",
        "        return dist_n, jnp.stack(out_carries, axis=0)\n",
        "\n",
        "\n",
        "class Critic(eqx.Module):\n",
        "    \"\"\"Critic for the walking task.\"\"\"\n",
        "\n",
        "    input_proj: eqx.nn.Linear\n",
        "    rnns: tuple[eqx.nn.GRUCell, ...]\n",
        "    output_proj: eqx.nn.Linear\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        key: PRNGKeyArray,\n",
        "        *,\n",
        "        hidden_size: int,\n",
        "        depth: int,\n",
        "    ) -> None:\n",
        "        num_inputs = NUM_CRITIC_INPUTS\n",
        "        num_outputs = 1\n",
        "\n",
        "        # Project input to hidden size\n",
        "        key, input_proj_key = jax.random.split(key)\n",
        "        self.input_proj = eqx.nn.Linear(\n",
        "            in_features=num_inputs,\n",
        "            out_features=hidden_size,\n",
        "            key=input_proj_key,\n",
        "        )\n",
        "\n",
        "        # Create RNN layer\n",
        "        key, rnn_key = jax.random.split(key)\n",
        "        self.rnns = tuple(\n",
        "            [\n",
        "                eqx.nn.GRUCell(\n",
        "                    input_size=hidden_size,\n",
        "                    hidden_size=hidden_size,\n",
        "                    key=rnn_key,\n",
        "                )\n",
        "                for _ in range(depth)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Project to output\n",
        "        self.output_proj = eqx.nn.Linear(\n",
        "            in_features=hidden_size,\n",
        "            out_features=num_outputs,\n",
        "            key=key,\n",
        "        )\n",
        "\n",
        "    def forward(self, obs_n: Array, carry: Array) -> tuple[Array, Array]:\n",
        "        x_n = self.input_proj(obs_n)\n",
        "        out_carries = []\n",
        "        for i, rnn in enumerate(self.rnns):\n",
        "            x_n = rnn(x_n, carry[i])\n",
        "            out_carries.append(x_n)\n",
        "        out_n = self.output_proj(x_n)\n",
        "\n",
        "        return out_n, jnp.stack(out_carries, axis=0)\n",
        "\n",
        "\n",
        "class Model(eqx.Module):\n",
        "    actor: Actor\n",
        "    critic: Critic\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        key: PRNGKeyArray,\n",
        "        *,\n",
        "        num_inputs: int,\n",
        "        num_outputs: int,\n",
        "        min_std: float,\n",
        "        max_std: float,\n",
        "        hidden_size: int,\n",
        "        num_mixtures: int,\n",
        "        depth: int,\n",
        "    ) -> None:\n",
        "        self.actor = Actor(\n",
        "            key,\n",
        "            num_inputs=num_inputs,\n",
        "            num_outputs=num_outputs,\n",
        "            min_std=min_std,\n",
        "            max_std=max_std,\n",
        "            var_scale=0.5,\n",
        "            hidden_size=hidden_size,\n",
        "            num_mixtures=num_mixtures,\n",
        "            depth=depth,\n",
        "        )\n",
        "        self.critic = Critic(\n",
        "            key,\n",
        "            hidden_size=hidden_size,\n",
        "            depth=depth,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7",
      "metadata": {
        "id": "7"
      },
      "source": [
        "## Config\n",
        "\n",
        "The [ksim framework](https://github.com/kscalelabs/ksim) is based on [xax](https://github.com/kscalelabs/xax), a Jax training library built by K-Scale. To provide configuration options, Xax uses a Config dataclass to parse command-line options. We define the config here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8",
      "metadata": {
        "id": "8"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class HumanoidWalkingTaskConfig(ksim.PPOConfig):\n",
        "    \"\"\"Config for the humanoid walking task.\"\"\"\n",
        "\n",
        "    # Model parameters.\n",
        "    hidden_size: int = xax.field(\n",
        "        value=128,\n",
        "        help=\"The hidden size for the MLPs.\",\n",
        "    )\n",
        "    depth: int = xax.field(\n",
        "        value=5,\n",
        "        help=\"The depth for the MLPs.\",\n",
        "    )\n",
        "    num_mixtures: int = xax.field(\n",
        "        value=5,\n",
        "        help=\"The number of mixtures for the actor.\",\n",
        "    )\n",
        "    scale: float = xax.field(\n",
        "        value=0.1,\n",
        "        help=\"The maximum position delta on each step, in radians.\",\n",
        "    )\n",
        "\n",
        "    # Optimizer parameters.\n",
        "    learning_rate: float = xax.field(\n",
        "        value=3e-4,\n",
        "        help=\"Learning rate for PPO.\",\n",
        "    )\n",
        "    max_grad_norm: float = xax.field(\n",
        "        value=2.0,\n",
        "        help=\"Maximum gradient norm for clipping.\",\n",
        "    )\n",
        "    adam_weight_decay: float = xax.field(\n",
        "        value=1e-5,\n",
        "        help=\"Weight decay for the Adam optimizer.\",\n",
        "    )\n",
        "\n",
        "    # Curriculum parameters.\n",
        "    num_curriculum_levels: int = xax.field(\n",
        "        value=10,\n",
        "        help=\"The number of curriculum levels to use.\",\n",
        "    )\n",
        "    increase_threshold: float = xax.field(\n",
        "        value=3.0,\n",
        "        help=\"Increase the curriculum level when the mean trajectory length is above this threshold.\",\n",
        "    )\n",
        "    decrease_threshold: float = xax.field(\n",
        "        value=1.0,\n",
        "        help=\"Decrease the curriculum level when the mean trajectory length is below this threshold.\",\n",
        "    )\n",
        "    min_level_steps: int = xax.field(\n",
        "        value=50,\n",
        "        help=\"The minimum number of steps to wait before changing the curriculum level.\",\n",
        "    )\n",
        "    min_curriculum_level: float = xax.field(\n",
        "        value=0.0,\n",
        "        help=\"The minimum curriculum level to use.\",\n",
        "    )\n",
        "\n",
        "    # Rendering parameters.\n",
        "    render_track_body_id: int | None = xax.field(\n",
        "        value=0,\n",
        "        help=\"The body id to track with the render camera.\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9",
      "metadata": {
        "id": "9"
      },
      "source": [
        "## Task\n",
        "\n",
        "The meat-and-potatoes of our training code is the task. This defines the observations, rewards, model calling logic, and everything else needed by `ksim` to train our reinforcement learning agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "10",
      "metadata": {
        "id": "10"
      },
      "outputs": [],
      "source": [
        "class HumanoidWalkingTask(ksim.PPOTask[HumanoidWalkingTaskConfig]):\n",
        "    def get_optimizer(self) -> optax.GradientTransformation:\n",
        "        optimizer = optax.chain(\n",
        "            optax.clip_by_global_norm(self.config.max_grad_norm),\n",
        "            (\n",
        "                optax.adam(self.config.learning_rate)\n",
        "                if self.config.adam_weight_decay == 0.0\n",
        "                else optax.adamw(self.config.learning_rate, weight_decay=self.config.adam_weight_decay)\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def get_mujoco_model(self) -> mujoco.MjModel:\n",
        "        mjcf_path = asyncio.run(ksim.get_mujoco_model_path(\"kbot-v2-feet\", name=\"robot\"))\n",
        "        return mujoco_scenes.mjcf.load_mjmodel(mjcf_path, scene=\"smooth\")\n",
        "\n",
        "    def get_mujoco_model_metadata(self, mj_model: mujoco.MjModel) -> dict[str, JointMetadataOutput]:\n",
        "        metadata = asyncio.run(ksim.get_mujoco_model_metadata(\"kbot-v2-feet\"))\n",
        "        if metadata.joint_name_to_metadata is None:\n",
        "            raise ValueError(\"Joint metadata is not available\")\n",
        "        return metadata.joint_name_to_metadata\n",
        "\n",
        "    def get_actuators(\n",
        "        self,\n",
        "        physics_model: ksim.PhysicsModel,\n",
        "        metadata: dict[str, JointMetadataOutput] | None = None,\n",
        "    ) -> ksim.Actuators:\n",
        "        assert metadata is not None, \"Metadata is required\"\n",
        "        return ksim.MITPositionActuators(\n",
        "            physics_model=physics_model,\n",
        "            joint_name_to_metadata=metadata,\n",
        "            ctrl_clip=[\n",
        "                # right arm\n",
        "                MAX_TORQUE[\"03\"],\n",
        "                MAX_TORQUE[\"03\"],\n",
        "                MAX_TORQUE[\"02\"],\n",
        "                MAX_TORQUE[\"02\"],\n",
        "                MAX_TORQUE[\"00\"],\n",
        "                # left arm\n",
        "                MAX_TORQUE[\"03\"],\n",
        "                MAX_TORQUE[\"03\"],\n",
        "                MAX_TORQUE[\"02\"],\n",
        "                MAX_TORQUE[\"02\"],\n",
        "                MAX_TORQUE[\"00\"],\n",
        "                # right leg\n",
        "                MAX_TORQUE[\"04\"],\n",
        "                MAX_TORQUE[\"03\"],\n",
        "                MAX_TORQUE[\"03\"],\n",
        "                MAX_TORQUE[\"04\"],\n",
        "                MAX_TORQUE[\"02\"],\n",
        "                # left leg\n",
        "                MAX_TORQUE[\"04\"],\n",
        "                MAX_TORQUE[\"03\"],\n",
        "                MAX_TORQUE[\"03\"],\n",
        "                MAX_TORQUE[\"04\"],\n",
        "                MAX_TORQUE[\"02\"],\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    def get_physics_randomizers(self, physics_model: ksim.PhysicsModel) -> list[ksim.PhysicsRandomizer]:\n",
        "        return [\n",
        "            ksim.StaticFrictionRandomizer(),\n",
        "            ksim.FloorFrictionRandomizer.from_geom_name(physics_model, \"floor\", scale_lower=0.8, scale_upper=1.2),\n",
        "            ksim.ArmatureRandomizer(),\n",
        "            ksim.AllBodiesMassMultiplicationRandomizer(scale_lower=0.95, scale_upper=1.05),\n",
        "            ksim.JointDampingRandomizer(),\n",
        "            ksim.JointZeroPositionRandomizer(scale_lower=math.radians(-2), scale_upper=math.radians(2)),\n",
        "        ]\n",
        "\n",
        "    def get_events(self, physics_model: ksim.PhysicsModel) -> list[ksim.Event]:\n",
        "        return [\n",
        "            ksim.PushEvent(\n",
        "                x_force=1.5,\n",
        "                y_force=1.5,\n",
        "                z_force=0.1,\n",
        "                x_angular_force=0.1,\n",
        "                y_angular_force=0.1,\n",
        "                z_angular_force=0.3,\n",
        "                interval_range=(0.5, 4.0),\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "    def get_resets(self, physics_model: ksim.PhysicsModel) -> list[ksim.Reset]:\n",
        "        return [\n",
        "            ksim.RandomJointPositionReset.create(physics_model, {k: v for k, v in ZEROS}, scale=0.1),\n",
        "            ksim.RandomJointVelocityReset(),\n",
        "        ]\n",
        "\n",
        "    def get_observations(self, physics_model: ksim.PhysicsModel) -> list[ksim.Observation]:\n",
        "        return [\n",
        "            ksim.JointPositionObservation(),\n",
        "            ksim.JointVelocityObservation(),\n",
        "            ksim.ActuatorForceObservation(),\n",
        "            ksim.CenterOfMassInertiaObservation(),\n",
        "            ksim.CenterOfMassVelocityObservation(),\n",
        "            ksim.BasePositionObservation(),\n",
        "            ksim.BaseOrientationObservation(),\n",
        "            ksim.BaseLinearVelocityObservation(),\n",
        "            ksim.BaseAngularVelocityObservation(),\n",
        "            ksim.BaseLinearAccelerationObservation(),\n",
        "            ksim.BaseAngularAccelerationObservation(),\n",
        "            ksim.ProjectedGravityObservation.create(\n",
        "                physics_model=physics_model,\n",
        "                framequat_name=\"base_link_quat\",\n",
        "                lag_range=(0.0, 0.5),\n",
        "            ),\n",
        "            ksim.ActuatorAccelerationObservation(),\n",
        "            ksim.BasePositionObservation(),\n",
        "            ksim.BaseOrientationObservation(),\n",
        "            ksim.BaseLinearVelocityObservation(),\n",
        "            ksim.BaseAngularVelocityObservation(),\n",
        "            ksim.CenterOfMassVelocityObservation(),\n",
        "            ksim.SensorObservation.create(physics_model=physics_model, sensor_name=\"imu_acc\"),\n",
        "            ksim.SensorObservation.create(physics_model=physics_model, sensor_name=\"imu_gyro\"),\n",
        "        ]\n",
        "\n",
        "    def get_commands(self, physics_model: ksim.PhysicsModel) -> list[ksim.Command]:\n",
        "        return []\n",
        "\n",
        "    def get_rewards(self, physics_model: ksim.PhysicsModel) -> list[ksim.Reward]:\n",
        "        return [\n",
        "            # Standard rewards.\n",
        "            ksim.StayAliveReward(scale=1.0),\n",
        "            ksim.NaiveForwardReward(clip_min=0.0, clip_max=0.5, scale=1.0),\n",
        "            ksim.UprightReward(index=\"x\", inverted=False, scale=0.1),\n",
        "            # Normalization penalties.\n",
        "            ksim.ActionInBoundsReward.create(physics_model, scale=0.01),\n",
        "            ksim.ActionSmoothnessPenalty(scale=-0.01),\n",
        "            ksim.ActuatorJerkPenalty(ctrl_dt=self.config.ctrl_dt, scale=-0.001),\n",
        "            ksim.ActuatorRelativeForcePenalty.create(physics_model, scale=-0.001),\n",
        "            ksim.AngularVelocityPenalty(index=\"x\", scale=-0.0005),\n",
        "            ksim.AngularVelocityPenalty(index=\"y\", scale=-0.0005),\n",
        "            ksim.AngularVelocityPenalty(index=\"z\", scale=-0.0005),\n",
        "            ksim.LinearVelocityPenalty(index=\"y\", scale=-0.0005),\n",
        "            ksim.LinearVelocityPenalty(index=\"z\", scale=-0.0005),\n",
        "            # Bespoke rewards.\n",
        "            BentArmPenalty.create(physics_model, scale=-0.01),\n",
        "        ]\n",
        "\n",
        "    def get_terminations(self, physics_model: ksim.PhysicsModel) -> list[ksim.Termination]:\n",
        "        return [\n",
        "            ksim.BadZTermination(unhealthy_z_lower=0.9, unhealthy_z_upper=1.6),\n",
        "            ksim.PitchTooGreatTermination(max_pitch=math.radians(30)),\n",
        "            ksim.RollTooGreatTermination(max_roll=math.radians(30)),\n",
        "            ksim.HighVelocityTermination(),\n",
        "            ksim.FarFromOriginTermination(max_dist=10.0),\n",
        "        ]\n",
        "\n",
        "    def get_curriculum(self, physics_model: ksim.PhysicsModel) -> ksim.Curriculum:\n",
        "        return ksim.EpisodeLengthCurriculum(\n",
        "            num_levels=self.config.num_curriculum_levels,\n",
        "            increase_threshold=self.config.increase_threshold,\n",
        "            decrease_threshold=self.config.decrease_threshold,\n",
        "            min_level_steps=self.config.min_level_steps,\n",
        "            dt=self.config.ctrl_dt,\n",
        "            min_level=self.config.min_curriculum_level,\n",
        "        )\n",
        "\n",
        "    def get_model(self, key: PRNGKeyArray) -> Model:\n",
        "        return Model(\n",
        "            key,\n",
        "            num_inputs=NUM_ACTOR_INPUTS,\n",
        "            num_outputs=NUM_JOINTS,\n",
        "            min_std=0.01,\n",
        "            max_std=1.0,\n",
        "            hidden_size=self.config.hidden_size,\n",
        "            num_mixtures=self.config.num_mixtures,\n",
        "            depth=self.config.depth,\n",
        "        )\n",
        "\n",
        "    def run_actor(\n",
        "        self,\n",
        "        model: Actor,\n",
        "        observations: xax.FrozenDict[str, Array],\n",
        "        commands: xax.FrozenDict[str, Array],\n",
        "        carry: Array,\n",
        "    ) -> tuple[distrax.Distribution, Array]:\n",
        "        joint_pos_n = observations[\"joint_position_observation\"]\n",
        "        joint_vel_n = observations[\"joint_velocity_observation\"]\n",
        "        proj_grav_3 = observations[\"projected_gravity_observation\"]\n",
        "\n",
        "        obs_n = jnp.concatenate(\n",
        "            [\n",
        "                joint_pos_n,  # NUM_JOINTS\n",
        "                joint_vel_n,  # NUM_JOINTS\n",
        "                proj_grav_3,  # 3\n",
        "            ],\n",
        "            axis=-1,\n",
        "        )\n",
        "\n",
        "        action, carry = model.forward(obs_n, carry)\n",
        "\n",
        "        return action, carry\n",
        "\n",
        "    def run_critic(\n",
        "        self,\n",
        "        model: Critic,\n",
        "        observations: xax.FrozenDict[str, Array],\n",
        "        commands: xax.FrozenDict[str, Array],\n",
        "        carry: Array,\n",
        "    ) -> tuple[Array, Array]:\n",
        "        dh_joint_pos_j = observations[\"joint_position_observation\"]\n",
        "        dh_joint_vel_j = observations[\"joint_velocity_observation\"]\n",
        "        com_inertia_n = observations[\"center_of_mass_inertia_observation\"]\n",
        "        com_vel_n = observations[\"center_of_mass_velocity_observation\"]\n",
        "        imu_acc_3 = observations[\"sensor_observation_imu_acc\"]\n",
        "        imu_gyro_3 = observations[\"sensor_observation_imu_gyro\"]\n",
        "        proj_grav_3 = observations[\"projected_gravity_observation\"]\n",
        "        act_frc_obs_n = observations[\"actuator_force_observation\"]\n",
        "        base_pos_3 = observations[\"base_position_observation\"]\n",
        "        base_quat_4 = observations[\"base_orientation_observation\"]\n",
        "\n",
        "        obs_n = jnp.concatenate(\n",
        "            [\n",
        "                dh_joint_pos_j,  # NUM_JOINTS\n",
        "                dh_joint_vel_j / 10.0,  # NUM_JOINTS\n",
        "                com_inertia_n,  # 160\n",
        "                com_vel_n,  # 96\n",
        "                imu_acc_3,  # 3\n",
        "                imu_gyro_3,  # 3\n",
        "                proj_grav_3,  # 3\n",
        "                act_frc_obs_n / 100.0,  # NUM_JOINTS\n",
        "                base_pos_3,  # 3\n",
        "                base_quat_4,  # 4\n",
        "            ],\n",
        "            axis=-1,\n",
        "        )\n",
        "\n",
        "        return model.forward(obs_n, carry)\n",
        "\n",
        "    def get_ppo_variables(\n",
        "        self,\n",
        "        model: Model,\n",
        "        trajectory: ksim.Trajectory,\n",
        "        model_carry: tuple[Array, Array],\n",
        "        rng: PRNGKeyArray,\n",
        "    ) -> tuple[ksim.PPOVariables, tuple[Array, Array]]:\n",
        "        def scan_fn(\n",
        "            actor_critic_carry: tuple[Array, Array],\n",
        "            transition: ksim.Trajectory,\n",
        "        ) -> tuple[tuple[Array, Array], ksim.PPOVariables]:\n",
        "            actor_carry, critic_carry = actor_critic_carry\n",
        "            actor_dist, next_actor_carry = self.run_actor(\n",
        "                model=model.actor,\n",
        "                observations=transition.obs,\n",
        "                commands=transition.command,\n",
        "                carry=actor_carry,\n",
        "            )\n",
        "            log_probs = actor_dist.log_prob(transition.action)\n",
        "            assert isinstance(log_probs, Array)\n",
        "            value, next_critic_carry = self.run_critic(\n",
        "                model=model.critic,\n",
        "                observations=transition.obs,\n",
        "                commands=transition.command,\n",
        "                carry=critic_carry,\n",
        "            )\n",
        "\n",
        "            transition_ppo_variables = ksim.PPOVariables(\n",
        "                log_probs=log_probs,\n",
        "                values=value.squeeze(-1),\n",
        "            )\n",
        "\n",
        "            next_carry = jax.tree.map(\n",
        "                lambda x, y: jnp.where(transition.done, x, y),\n",
        "                self.get_initial_model_carry(rng),\n",
        "                (next_actor_carry, next_critic_carry),\n",
        "            )\n",
        "\n",
        "            return next_carry, transition_ppo_variables\n",
        "\n",
        "        next_model_carry, ppo_variables = jax.lax.scan(scan_fn, model_carry, trajectory)\n",
        "\n",
        "        return ppo_variables, next_model_carry\n",
        "\n",
        "    def get_initial_model_carry(self, rng: PRNGKeyArray) -> tuple[Array, Array]:\n",
        "        return (\n",
        "            jnp.zeros(shape=(self.config.depth, self.config.hidden_size)),\n",
        "            jnp.zeros(shape=(self.config.depth, self.config.hidden_size)),\n",
        "        )\n",
        "\n",
        "    def sample_action(\n",
        "        self,\n",
        "        model: Model,\n",
        "        model_carry: tuple[Array, Array],\n",
        "        physics_model: ksim.PhysicsModel,\n",
        "        physics_state: ksim.PhysicsState,\n",
        "        observations: xax.FrozenDict[str, Array],\n",
        "        commands: xax.FrozenDict[str, Array],\n",
        "        rng: PRNGKeyArray,\n",
        "        argmax: bool,\n",
        "    ) -> ksim.Action:\n",
        "        actor_carry_in, critic_carry_in = model_carry\n",
        "\n",
        "        # Runs the actor model to get the action distribution.\n",
        "        action_dist_j, actor_carry = self.run_actor(\n",
        "            model=model.actor,\n",
        "            observations=observations,\n",
        "            commands=commands,\n",
        "            carry=actor_carry_in,\n",
        "        )\n",
        "\n",
        "        action_j = action_dist_j.mode() if argmax else action_dist_j.sample(seed=rng)\n",
        "\n",
        "        return ksim.Action(\n",
        "            action=action_j,\n",
        "            carry=(actor_carry, critic_carry_in),\n",
        "            aux_outputs=None,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11",
      "metadata": {
        "id": "11"
      },
      "source": [
        "## Launching an Experiment\n",
        "\n",
        "To launch an experiment with `xax`, you can use `Task.launch(config)`. Note that this is usually intended to be called from the command-line, so it will by default attempt to parse additional command-line arguments unless `use_cli=False` is set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12",
        "outputId": "b37b0dca-fc55-445b-f175-4f4d533bd22b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31m┌────────────────────────────────────────────────────────────┐\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;91mNo config file was found in /root/.xax.yml; writing one...\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m└────────────────────────────────────────────────────────────┘\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xax.task.base:Could not resolve task path for HumanoidWalkingTask, returning current working directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33mWARNING\u001b[0m \u001b[90m2025-05-02 22:13:22\u001b[0m [\u001b[1;34mxax.task.base\u001b[0m] Could not resolve task path for HumanoidWalkingTask, returning current working directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.compile:Setting JAX logging level to INFO\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:22\u001b[0m [\u001b[1;34mxax.task.mixins.compile\u001b[0m] Setting JAX logging level to INFO\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.compile:Setting JAX compilation cache directory to /root/.cache/jax/jaxcache\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:22\u001b[0m [\u001b[1;34mxax.task.mixins.compile\u001b[0m] Setting JAX compilation cache directory to /root/.cache/jax/jaxcache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.compile:Configuring JAX compilation cache parameters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:22\u001b[0m [\u001b[1;34mxax.task.mixins.compile\u001b[0m] Configuring JAX compilation cache parameters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:2025-05-02 22:13:23,760:jax._src.xla_bridge:924: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
            "INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:23\u001b[0m [\u001b[1;34mjax._src.xla_bridge\u001b[0m] Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:2025-05-02 22:13:23,788:jax._src.xla_bridge:924: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n",
            "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:23\u001b[0m [\u001b[1;34mjax._src.xla_bridge\u001b[0m] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xax.task.mixins.artifacts:Could not resolve task path for HumanoidWalkingTask, returning current working directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33mWARNING\u001b[0m \u001b[90m2025-05-02 22:13:25\u001b[0m [\u001b[1;34mxax.task.mixins.artifacts\u001b[0m] Could not resolve task path for HumanoidWalkingTask, returning current working directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "STATUS:xax.task.mixins.artifacts:/content/humanoid_walking_task/run_0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u001b[1;32mSTATUS\u001b[0m \u001b[90m2025-05-02 22:13:25\u001b[0m [\u001b[1;34mxax.task.mixins.artifacts\u001b[0m] /content/humanoid_walking_task/run_0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xax.task.base:Could not resolve task path for %s, returning current working directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33mWARNING\u001b[0m \u001b[90m2025-05-02 22:13:25\u001b[0m [\u001b[1;34mxax.task.base\u001b[0m] Could not resolve task path for %s, returning current working directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/kscale/conf.py:44: UserWarning: Settings directory does not exist: /root/.kscale. Creating it now.\n",
            "  warnings.warn(f\"Settings directory does not exist: {dir_path}. Creating it now.\")\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33mWARNING\u001b[0m \u001b[90m2025-05-02 22:13:25\u001b[0m [\u001b[1;34mpy.warnings\u001b[0m] /usr/local/lib/python3.11/dist-packages/kscale/conf.py:44: UserWarning: Settings directory does not exist: /root/.kscale. Creating it now.\n",
            "  warnings.warn(f\"Settings directory does not exist: {dir_path}. Creating it now.\")\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "STATUS:xax.task.mixins.train:/content\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u001b[1;32mSTATUS\u001b[0m \u001b[90m2025-05-02 22:13:25\u001b[0m [\u001b[1;34mxax.task.mixins.train\u001b[0m] /content\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "STATUS:xax.task.mixins.train:humanoid_walking_task\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u001b[1;32mSTATUS\u001b[0m \u001b[90m2025-05-02 22:13:25\u001b[0m [\u001b[1;34mxax.task.mixins.train\u001b[0m] humanoid_walking_task\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "STATUS:xax.task.mixins.train:JAX devices: [CudaDevice(id=0)]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u001b[1;32mSTATUS\u001b[0m \u001b[90m2025-05-02 22:13:25\u001b[0m [\u001b[1;34mxax.task.mixins.train\u001b[0m] JAX devices: [CudaDevice(id=0)]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xax.task.base:Could not resolve task path for HumanoidWalkingTask, returning current working directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;33mWARNING\u001b[0m \u001b[90m2025-05-02 22:13:25\u001b[0m [\u001b[1;34mxax.task.base\u001b[0m] Could not resolve task path for HumanoidWalkingTask, returning current working directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://api.kscale.dev/robots/urdf/kbot-v2-feet \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:26\u001b[0m [\u001b[1;34mhttpx\u001b[0m] HTTP Request: GET https://api.kscale.dev/robots/urdf/kbot-v2-feet \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:kscale.web.clients.robot_class:Downloading URDF file from https://kscale-www-production.s3.amazonaws.com/urdfs/81d7c38e0690537e/robot.tgz?AWSAccessKeyId=ASIA2R4HRCAH4IJGHQEC&Signature=7dn5jhz2suGee4wQJOI7IU%2BusSE%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEEYaCXVzLWVhc3QtMSJHMEUCIQDKeUPH6mSTaWmge7NSWzZ%2F%2FsrmIp3MeyQFSz812iNAugIgRx7GGXWQIB0pOVdkiDCeUnB3FUvvQuS1TBfJYNzLlYkq6gII3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw3MjU1OTY4MzU4NTUiDBlczJNUQg75%2B1tkHyq%2BApe847C3oV33Ur%2BFa2nOyobu15iBog8JAG%2F1kIXex3%2B%2BnyrEsPAv%2BG7caLjlah5WHbWiM0WB6alilFxeyrT%2BzQpnAJ6Prk40eobgQDbyLUVDMPZ9wnlpqaLKdowoebRb6UIVlSfbzWokELzwbRkkfpIMrEXJ4ioQE1hLLHMdUH6hj4JCc%2BvvwjhO2KuYMRvnFKvC%2FcAcYwshlL1sfmjit146YwAnIV%2FYAAkUOBuF7GzNxPc0zDZkqW1SMk68DNr3JaiP0sbcejSEcY%2FbASHQ8dOZ4qKbWoX%2BcGMiz%2BY3IDPL7sUCUcQ2SOxEtp3eogQcEZHT%2Bjs2LeAC%2FYmsp0vlut4PMDln4hW73BT7Y7e%2B5nIH6sV8AXKz1gY6NhFHcpekJSzKmueE3dWCZZNHQt43gHWaQETfRJP7ijaRnTdq1jDN%2F9TABjqPARuwhVSOLo%2BjewGPs4f5gTTVl8pJF7gutdDqAnVy3lYh2qbsWFFVCgV88voNVGhpC0%2Bp086%2F6bw1P0DKtVlJCJE8zZD9o%2B7VWWGG1%2BMJBQfpcR%2F1mfDFZM0oQ9I2pkT%2FNpO76MFjgsXa9gTZdt%2Fu0k25wvnjb4WAS7dYPjtOIoRMb6bfniT6Yka8DXegLZWA&Expires=1746227606\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:26\u001b[0m [\u001b[1;34mkscale.web.clients.robot_class\u001b[0m] Downloading URDF file from https://kscale-www-production.s3.amazonaws.com/urdfs/81d7c38e0690537e/robot.tgz?AWSAccessKeyId=ASIA2R4HRCAH4IJGHQEC&Signature=7dn5jhz2suGee4wQJOI7IU%2BusSE%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEEYaCXVzLWVhc3QtMSJHMEUCIQDKeUPH6mSTaWmge7NSWzZ%2F%2FsrmIp3MeyQFSz812iNAugIgRx7GGXWQIB0pOVdkiDCeUnB3FUvvQuS1TBfJYNzLlYkq6gII3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw3MjU1OTY4MzU4NTUiDBlczJNUQg75%2B1tkHyq%2BApe847C3oV33Ur%2BFa2nOyobu15iBog8JAG%2F1kIXex3%2B%2BnyrEsPAv%2BG7caLjlah5WHbWiM0WB6alilFxeyrT%2BzQpnAJ6Prk40eobgQDbyLUVDMPZ9wnlpqaLKdowoebRb6UIVlSfbzWokELzwbRkkfpIMrEXJ4ioQE1hLLHMdUH6hj4JCc%2BvvwjhO2KuYMRvnFKvC%2FcAcYwshlL1sfmjit146YwAnIV%2FYAAkUOBuF7GzNxPc0zDZkqW1SMk68DNr3JaiP0sbcejSEcY%2FbASHQ8dOZ4qKbWoX%2BcGMiz%2BY3IDPL7sUCUcQ2SOxEtp3eogQcEZHT%2Bjs2LeAC%2FYmsp0vlut4PMDln4hW73BT7Y7e%2B5nIH6sV8AXKz1gY6NhFHcpekJSzKmueE3dWCZZNHQt43gHWaQETfRJP7ijaRnTdq1jDN%2F9TABjqPARuwhVSOLo%2BjewGPs4f5gTTVl8pJF7gutdDqAnVy3lYh2qbsWFFVCgV88voNVGhpC0%2Bp086%2F6bw1P0DKtVlJCJE8zZD9o%2B7VWWGG1%2BMJBQfpcR%2F1mfDFZM0oQ9I2pkT%2FNpO76MFjgsXa9gTZdt%2Fu0k25wvnjb4WAS7dYPjtOIoRMb6bfniT6Yka8DXegLZWA&Expires=1746227606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://kscale-www-production.s3.amazonaws.com/urdfs/81d7c38e0690537e/robot.tgz?AWSAccessKeyId=ASIA2R4HRCAH4IJGHQEC&Signature=7dn5jhz2suGee4wQJOI7IU%2BusSE%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEEYaCXVzLWVhc3QtMSJHMEUCIQDKeUPH6mSTaWmge7NSWzZ%2F%2FsrmIp3MeyQFSz812iNAugIgRx7GGXWQIB0pOVdkiDCeUnB3FUvvQuS1TBfJYNzLlYkq6gII3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw3MjU1OTY4MzU4NTUiDBlczJNUQg75%2B1tkHyq%2BApe847C3oV33Ur%2BFa2nOyobu15iBog8JAG%2F1kIXex3%2B%2BnyrEsPAv%2BG7caLjlah5WHbWiM0WB6alilFxeyrT%2BzQpnAJ6Prk40eobgQDbyLUVDMPZ9wnlpqaLKdowoebRb6UIVlSfbzWokELzwbRkkfpIMrEXJ4ioQE1hLLHMdUH6hj4JCc%2BvvwjhO2KuYMRvnFKvC%2FcAcYwshlL1sfmjit146YwAnIV%2FYAAkUOBuF7GzNxPc0zDZkqW1SMk68DNr3JaiP0sbcejSEcY%2FbASHQ8dOZ4qKbWoX%2BcGMiz%2BY3IDPL7sUCUcQ2SOxEtp3eogQcEZHT%2Bjs2LeAC%2FYmsp0vlut4PMDln4hW73BT7Y7e%2B5nIH6sV8AXKz1gY6NhFHcpekJSzKmueE3dWCZZNHQt43gHWaQETfRJP7ijaRnTdq1jDN%2F9TABjqPARuwhVSOLo%2BjewGPs4f5gTTVl8pJF7gutdDqAnVy3lYh2qbsWFFVCgV88voNVGhpC0%2Bp086%2F6bw1P0DKtVlJCJE8zZD9o%2B7VWWGG1%2BMJBQfpcR%2F1mfDFZM0oQ9I2pkT%2FNpO76MFjgsXa9gTZdt%2Fu0k25wvnjb4WAS7dYPjtOIoRMb6bfniT6Yka8DXegLZWA&Expires=1746227606 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:26\u001b[0m [\u001b[1;34mhttpx\u001b[0m] HTTP Request: GET https://kscale-www-production.s3.amazonaws.com/urdfs/81d7c38e0690537e/robot.tgz?AWSAccessKeyId=ASIA2R4HRCAH4IJGHQEC&Signature=7dn5jhz2suGee4wQJOI7IU%2BusSE%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEEYaCXVzLWVhc3QtMSJHMEUCIQDKeUPH6mSTaWmge7NSWzZ%2F%2FsrmIp3MeyQFSz812iNAugIgRx7GGXWQIB0pOVdkiDCeUnB3FUvvQuS1TBfJYNzLlYkq6gII3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw3MjU1OTY4MzU4NTUiDBlczJNUQg75%2B1tkHyq%2BApe847C3oV33Ur%2BFa2nOyobu15iBog8JAG%2F1kIXex3%2B%2BnyrEsPAv%2BG7caLjlah5WHbWiM0WB6alilFxeyrT%2BzQpnAJ6Prk40eobgQDbyLUVDMPZ9wnlpqaLKdowoebRb6UIVlSfbzWokELzwbRkkfpIMrEXJ4ioQE1hLLHMdUH6hj4JCc%2BvvwjhO2KuYMRvnFKvC%2FcAcYwshlL1sfmjit146YwAnIV%2FYAAkUOBuF7GzNxPc0zDZkqW1SMk68DNr3JaiP0sbcejSEcY%2FbASHQ8dOZ4qKbWoX%2BcGMiz%2BY3IDPL7sUCUcQ2SOxEtp3eogQcEZHT%2Bjs2LeAC%2FYmsp0vlut4PMDln4hW73BT7Y7e%2B5nIH6sV8AXKz1gY6NhFHcpekJSzKmueE3dWCZZNHQt43gHWaQETfRJP7ijaRnTdq1jDN%2F9TABjqPARuwhVSOLo%2BjewGPs4f5gTTVl8pJF7gutdDqAnVy3lYh2qbsWFFVCgV88voNVGhpC0%2Bp086%2F6bw1P0DKtVlJCJE8zZD9o%2B7VWWGG1%2BMJBQfpcR%2F1mfDFZM0oQ9I2pkT%2FNpO76MFjgsXa9gTZdt%2Fu0k25wvnjb4WAS7dYPjtOIoRMb6bfniT6Yka8DXegLZWA&Expires=1746227606 \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:kscale.web.clients.robot_class:Checking MD5 hash of downloaded file\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:27\u001b[0m [\u001b[1;34mkscale.web.clients.robot_class\u001b[0m] Checking MD5 hash of downloaded file\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:kscale.web.clients.robot_class:Updating downloaded file information\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:27\u001b[0m [\u001b[1;34mkscale.web.clients.robot_class\u001b[0m] Updating downloaded file information\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:kscale.web.clients.robot_class:Unpacking URDF file\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:27\u001b[0m [\u001b[1;34mkscale.web.clients.robot_class\u001b[0m] Unpacking URDF file\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:kscale.web.clients.robot_class:Updating downloaded file information\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:27\u001b[0m [\u001b[1;34mkscale.web.clients.robot_class\u001b[0m] Updating downloaded file information\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.train:Starting a new training run\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:28\u001b[0m [\u001b[1;34mxax.task.mixins.train\u001b[0m] Starting a new training run\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PING:ksim.task.rl:Model size: 1,089,581 parameters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;35mPING\u001b[0m  \u001b[90m2025-05-02 22:13:31\u001b[0m [\u001b[1;34mksim.task.rl\u001b[0m] Model size: 1,089,581 parameters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PING:ksim.task.rl:Optimizer size: 2,179,162 parameters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;35mPING\u001b[0m  \u001b[90m2025-05-02 22:13:31\u001b[0m [\u001b[1;34mksim.task.rl\u001b[0m] Optimizer size: 2,179,162 parameters\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: GET https://api.kscale.dev/robots/name/kbot-v2-feet \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:13:32\u001b[0m [\u001b[1;34mhttpx\u001b[0m] HTTP Request: GET https://api.kscale.dev/robots/name/kbot-v2-feet \"HTTP/1.1 200 OK\"\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m1\u001b[0m\n",
            " ↪ Samples: \u001b[36m102,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m0s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001238\n",
            " ↪ action_smoothness_penalty: -5.036e-05\n",
            " ↪ actuator_jerk_penalty: -6.031e-06\n",
            " ↪ actuator_relative_force_penalty: -5.12e-06\n",
            " ↪ bent_arm_penalty: -2.36e-05\n",
            " ↪ stay_alive_reward: 0.001084\n",
            " ↪ total: 0.004403\n",
            " ↪ upright_reward: 0.003135\n",
            " ↪ x_angular_velocity_penalty: -1.518e-05\n",
            " ↪ x_naive_forward_reward: 0.0002308\n",
            " ↪ y_angular_velocity_penalty: -3.02e-05\n",
            " ↪ y_linear_velocity_penalty: -3.103e-07\n",
            " ↪ z_angular_velocity_penalty: -3.812e-05\n",
            " ↪ z_linear_velocity_penalty: -2.335e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0\n",
            " ↪ dt: 235.1\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\n",
            "\u001b[1;90mPings\u001b[0m\n",
            " ✦ \u001b[36mOptimizer size: 2,179,162 parameters\u001b[0m\n",
            " ✦ \u001b[36mModel size: 1,089,581 parameters\u001b[0m\n",
            " ✦ \u001b[36mCould not resolve task path for HumanoidWalkingTask, returning current working directory\u001b[0m\n",
            " ✦ \u001b[36m/usr/local/lib/python3.11/dist-packages/kscale/conf.py:44: UserWarning: Settings directory does not exist: /root/.kscale. Creating it now.\n",
            "  warnings.warn(f\"Settings directory does not exist: {dir_path}. Creating it now.\")\n",
            "\u001b[0m\n",
            " ✦ \u001b[36mCould not resolve task path for %s, returning current working directory\u001b[0m\n",
            " ✦ \u001b[36mCould not resolve task path for HumanoidWalkingTask, returning current working directory\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "STATUS:ksim.task.rl:First step time: 2m, 53s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u001b[1;32mSTATUS\u001b[0m \u001b[90m2025-05-02 22:17:18\u001b[0m [\u001b[1;34mksim.task.rl\u001b[0m] First step time: 2m, 53s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "STATUS:root:Tensorboard: http://3521daa4530a:6036/\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u001b[1;32mSTATUS\u001b[0m \u001b[90m2025-05-02 22:17:26\u001b[0m [\u001b[1;34mroot\u001b[0m] Tensorboard: http://3521daa4530a:6036/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.1.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:17:35\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.1.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;33mvalid\u001b[0m\n",
            " ↪ Steps: \u001b[36m1\u001b[0m\n",
            " ↪ Samples: \u001b[36m102,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m2m, 53s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001239\n",
            " ↪ action_smoothness_penalty: -5.028e-05\n",
            " ↪ actuator_jerk_penalty: -6.001e-06\n",
            " ↪ actuator_relative_force_penalty: -5.231e-06\n",
            " ↪ bent_arm_penalty: -2.411e-05\n",
            " ↪ stay_alive_reward: 0.001023\n",
            " ↪ total: 0.004335\n",
            " ↪ upright_reward: 0.003132\n",
            " ↪ x_angular_velocity_penalty: -1.545e-05\n",
            " ↪ x_naive_forward_reward: 0.0002296\n",
            " ↪ y_angular_velocity_penalty: -3.013e-05\n",
            " ↪ y_linear_velocity_penalty: -3.795e-07\n",
            " ↪ z_angular_velocity_penalty: -3.982e-05\n",
            " ↪ z_linear_velocity_penalty: -2.061e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0\n",
            " ↪ dt: 253.1\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m2\u001b[0m\n",
            " ↪ Samples: \u001b[36m204,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m2m, 53s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001232\n",
            " ↪ action_smoothness_penalty: -5.003e-05\n",
            " ↪ actuator_jerk_penalty: -5.997e-06\n",
            " ↪ actuator_relative_force_penalty: -5.252e-06\n",
            " ↪ bent_arm_penalty: -2.418e-05\n",
            " ↪ stay_alive_reward: 0.001123\n",
            " ↪ total: 0.004456\n",
            " ↪ upright_reward: 0.00313\n",
            " ↪ x_angular_velocity_penalty: -1.569e-05\n",
            " ↪ x_naive_forward_reward: 0.000252\n",
            " ↪ y_angular_velocity_penalty: -2.886e-05\n",
            " ↪ y_linear_velocity_penalty: -4.181e-07\n",
            " ↪ z_angular_velocity_penalty: -4.008e-05\n",
            " ↪ z_linear_velocity_penalty: -1.934e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0\n",
            " ↪ dt: 49.54\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m3\u001b[0m\n",
            " ↪ Samples: \u001b[36m307,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m3m, 10s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001238\n",
            " ↪ action_smoothness_penalty: -4.952e-05\n",
            " ↪ actuator_jerk_penalty: -5.969e-06\n",
            " ↪ actuator_relative_force_penalty: -5.253e-06\n",
            " ↪ bent_arm_penalty: -2.421e-05\n",
            " ↪ stay_alive_reward: 0.001187\n",
            " ↪ total: 0.004557\n",
            " ↪ upright_reward: 0.003134\n",
            " ↪ x_angular_velocity_penalty: -1.573e-05\n",
            " ↪ x_naive_forward_reward: 0.0002833\n",
            " ↪ y_angular_velocity_penalty: -2.784e-05\n",
            " ↪ y_linear_velocity_penalty: -4.525e-07\n",
            " ↪ z_angular_velocity_penalty: -3.996e-05\n",
            " ↪ z_linear_velocity_penalty: -1.86e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.116\n",
            " ↪ dt: 17.24\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m4\u001b[0m\n",
            " ↪ Samples: \u001b[36m409,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m3m, 27s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001245\n",
            " ↪ action_smoothness_penalty: -4.907e-05\n",
            " ↪ actuator_jerk_penalty: -5.966e-06\n",
            " ↪ actuator_relative_force_penalty: -5.253e-06\n",
            " ↪ bent_arm_penalty: -2.424e-05\n",
            " ↪ stay_alive_reward: 0.001257\n",
            " ↪ total: 0.004692\n",
            " ↪ upright_reward: 0.003134\n",
            " ↪ x_angular_velocity_penalty: -1.564e-05\n",
            " ↪ x_naive_forward_reward: 0.0003466\n",
            " ↪ y_angular_velocity_penalty: -2.722e-05\n",
            " ↪ y_linear_velocity_penalty: -5.186e-07\n",
            " ↪ z_angular_velocity_penalty: -4.01e-05\n",
            " ↪ z_linear_velocity_penalty: -1.801e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.08662\n",
            " ↪ dt: 17.4\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m5\u001b[0m\n",
            " ↪ Samples: \u001b[36m512,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m3m, 45s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001261\n",
            " ↪ action_smoothness_penalty: -4.876e-05\n",
            " ↪ actuator_jerk_penalty: -5.93e-06\n",
            " ↪ actuator_relative_force_penalty: -5.265e-06\n",
            " ↪ bent_arm_penalty: -2.429e-05\n",
            " ↪ stay_alive_reward: 0.001341\n",
            " ↪ total: 0.004873\n",
            " ↪ upright_reward: 0.00313\n",
            " ↪ x_angular_velocity_penalty: -1.59e-05\n",
            " ↪ x_naive_forward_reward: 0.0004456\n",
            " ↪ y_angular_velocity_penalty: -2.704e-05\n",
            " ↪ y_linear_velocity_penalty: -5.89e-07\n",
            " ↪ z_angular_velocity_penalty: -4.042e-05\n",
            " ↪ z_linear_velocity_penalty: -1.733e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.07708\n",
            " ↪ dt: 17.26\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.5.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:19:16\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.5.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m6\u001b[0m\n",
            " ↪ Samples: \u001b[36m614,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m4m, 2s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001255\n",
            " ↪ action_smoothness_penalty: -4.839e-05\n",
            " ↪ actuator_jerk_penalty: -5.932e-06\n",
            " ↪ actuator_relative_force_penalty: -5.273e-06\n",
            " ↪ bent_arm_penalty: -2.446e-05\n",
            " ↪ stay_alive_reward: 0.00139\n",
            " ↪ total: 0.005039\n",
            " ↪ upright_reward: 0.003126\n",
            " ↪ x_angular_velocity_penalty: -1.572e-05\n",
            " ↪ x_naive_forward_reward: 0.0005677\n",
            " ↪ y_angular_velocity_penalty: -2.712e-05\n",
            " ↪ y_linear_velocity_penalty: -6.225e-07\n",
            " ↪ z_angular_velocity_penalty: -4.065e-05\n",
            " ↪ z_linear_velocity_penalty: -1.693e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.07236\n",
            " ↪ dt: 17.21\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m7\u001b[0m\n",
            " ↪ Samples: \u001b[36m716,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m4m, 20s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001274\n",
            " ↪ action_smoothness_penalty: -4.795e-05\n",
            " ↪ actuator_jerk_penalty: -5.929e-06\n",
            " ↪ actuator_relative_force_penalty: -5.264e-06\n",
            " ↪ bent_arm_penalty: -2.443e-05\n",
            " ↪ stay_alive_reward: 0.001434\n",
            " ↪ total: 0.005254\n",
            " ↪ upright_reward: 0.003121\n",
            " ↪ x_angular_velocity_penalty: -1.608e-05\n",
            " ↪ x_naive_forward_reward: 0.0007426\n",
            " ↪ y_angular_velocity_penalty: -2.703e-05\n",
            " ↪ y_linear_velocity_penalty: -6.642e-07\n",
            " ↪ z_angular_velocity_penalty: -4.101e-05\n",
            " ↪ z_linear_velocity_penalty: -1.695e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.06893\n",
            " ↪ dt: 17.94\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m8\u001b[0m\n",
            " ↪ Samples: \u001b[36m819,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m4m, 37s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001281\n",
            " ↪ action_smoothness_penalty: -4.754e-05\n",
            " ↪ actuator_jerk_penalty: -5.887e-06\n",
            " ↪ actuator_relative_force_penalty: -5.264e-06\n",
            " ↪ bent_arm_penalty: -2.443e-05\n",
            " ↪ stay_alive_reward: 0.001465\n",
            " ↪ total: 0.005486\n",
            " ↪ upright_reward: 0.003119\n",
            " ↪ x_angular_velocity_penalty: -1.578e-05\n",
            " ↪ x_naive_forward_reward: 0.0009426\n",
            " ↪ y_angular_velocity_penalty: -2.738e-05\n",
            " ↪ y_linear_velocity_penalty: -6.917e-07\n",
            " ↪ z_angular_velocity_penalty: -4.068e-05\n",
            " ↪ z_linear_velocity_penalty: -1.692e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.06704\n",
            " ↪ dt: 17.37\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m9\u001b[0m\n",
            " ↪ Samples: \u001b[36m921,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m4m, 54s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001295\n",
            " ↪ action_smoothness_penalty: -4.726e-05\n",
            " ↪ actuator_jerk_penalty: -5.907e-06\n",
            " ↪ actuator_relative_force_penalty: -5.257e-06\n",
            " ↪ bent_arm_penalty: -2.447e-05\n",
            " ↪ stay_alive_reward: 0.001494\n",
            " ↪ total: 0.005691\n",
            " ↪ upright_reward: 0.00311\n",
            " ↪ x_angular_velocity_penalty: -1.573e-05\n",
            " ↪ x_naive_forward_reward: 0.001127\n",
            " ↪ y_angular_velocity_penalty: -2.794e-05\n",
            " ↪ y_linear_velocity_penalty: -7.442e-07\n",
            " ↪ z_angular_velocity_penalty: -4.059e-05\n",
            " ↪ z_linear_velocity_penalty: -1.673e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.06572\n",
            " ↪ dt: 17.31\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.9.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:20:26\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.9.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m10\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,024,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m5m, 12s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001315\n",
            " ↪ action_smoothness_penalty: -4.684e-05\n",
            " ↪ actuator_jerk_penalty: -5.804e-06\n",
            " ↪ actuator_relative_force_penalty: -5.25e-06\n",
            " ↪ bent_arm_penalty: -2.46e-05\n",
            " ↪ stay_alive_reward: 0.001502\n",
            " ↪ total: 0.00587\n",
            " ↪ upright_reward: 0.003107\n",
            " ↪ x_angular_velocity_penalty: -1.56e-05\n",
            " ↪ x_naive_forward_reward: 0.001299\n",
            " ↪ y_angular_velocity_penalty: -2.8e-05\n",
            " ↪ y_linear_velocity_penalty: -7.809e-07\n",
            " ↪ z_angular_velocity_penalty: -4.108e-05\n",
            " ↪ z_linear_velocity_penalty: -1.64e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.06467\n",
            " ↪ dt: 17.45\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;33mvalid\u001b[0m\n",
            " ↪ Steps: \u001b[36m10\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,024,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m5m, 30s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001313\n",
            " ↪ action_smoothness_penalty: -4.665e-05\n",
            " ↪ actuator_jerk_penalty: -5.81e-06\n",
            " ↪ actuator_relative_force_penalty: -5.241e-06\n",
            " ↪ bent_arm_penalty: -2.46e-05\n",
            " ↪ stay_alive_reward: 0.001523\n",
            " ↪ total: 0.005957\n",
            " ↪ upright_reward: 0.003109\n",
            " ↪ x_angular_velocity_penalty: -1.563e-05\n",
            " ↪ x_naive_forward_reward: 0.001364\n",
            " ↪ y_angular_velocity_penalty: -2.824e-05\n",
            " ↪ y_linear_velocity_penalty: -7.909e-07\n",
            " ↪ z_angular_velocity_penalty: -4.1e-05\n",
            " ↪ z_linear_velocity_penalty: -1.618e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0\n",
            " ↪ dt: 188.7\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m11\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,126,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m5m, 30s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.000133\n",
            " ↪ action_smoothness_penalty: -4.628e-05\n",
            " ↪ actuator_jerk_penalty: -5.787e-06\n",
            " ↪ actuator_relative_force_penalty: -5.229e-06\n",
            " ↪ bent_arm_penalty: -2.46e-05\n",
            " ↪ stay_alive_reward: 0.001518\n",
            " ↪ total: 0.00607\n",
            " ↪ upright_reward: 0.003106\n",
            " ↪ x_angular_velocity_penalty: -1.548e-05\n",
            " ↪ x_naive_forward_reward: 0.001482\n",
            " ↪ y_angular_velocity_penalty: -2.862e-05\n",
            " ↪ y_linear_velocity_penalty: -8.063e-07\n",
            " ↪ z_angular_velocity_penalty: -4.043e-05\n",
            " ↪ z_linear_velocity_penalty: -1.615e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05597\n",
            " ↪ dt: 39.48\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m12\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,228,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m5m, 47s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001343\n",
            " ↪ action_smoothness_penalty: -4.596e-05\n",
            " ↪ actuator_jerk_penalty: -5.752e-06\n",
            " ↪ actuator_relative_force_penalty: -5.213e-06\n",
            " ↪ bent_arm_penalty: -2.459e-05\n",
            " ↪ stay_alive_reward: 0.001517\n",
            " ↪ total: 0.006249\n",
            " ↪ upright_reward: 0.003103\n",
            " ↪ x_angular_velocity_penalty: -1.523e-05\n",
            " ↪ x_naive_forward_reward: 0.001663\n",
            " ↪ y_angular_velocity_penalty: -2.878e-05\n",
            " ↪ y_linear_velocity_penalty: -7.685e-07\n",
            " ↪ z_angular_velocity_penalty: -4.069e-05\n",
            " ↪ z_linear_velocity_penalty: -1.622e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05613\n",
            " ↪ dt: 17.31\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m13\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,331,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m6m, 5s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001357\n",
            " ↪ action_smoothness_penalty: -4.561e-05\n",
            " ↪ actuator_jerk_penalty: -5.691e-06\n",
            " ↪ actuator_relative_force_penalty: -5.199e-06\n",
            " ↪ bent_arm_penalty: -2.457e-05\n",
            " ↪ stay_alive_reward: 0.001528\n",
            " ↪ total: 0.006373\n",
            " ↪ upright_reward: 0.003098\n",
            " ↪ x_angular_velocity_penalty: -1.513e-05\n",
            " ↪ x_naive_forward_reward: 0.001779\n",
            " ↪ y_angular_velocity_penalty: -2.868e-05\n",
            " ↪ y_linear_velocity_penalty: -7.984e-07\n",
            " ↪ z_angular_velocity_penalty: -4.05e-05\n",
            " ↪ z_linear_velocity_penalty: -1.606e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05625\n",
            " ↪ dt: 17.38\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.13.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:21:58\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.13.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m14\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,433,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m6m, 22s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001366\n",
            " ↪ action_smoothness_penalty: -4.522e-05\n",
            " ↪ actuator_jerk_penalty: -5.706e-06\n",
            " ↪ actuator_relative_force_penalty: -5.181e-06\n",
            " ↪ bent_arm_penalty: -2.454e-05\n",
            " ↪ stay_alive_reward: 0.001526\n",
            " ↪ total: 0.006497\n",
            " ↪ upright_reward: 0.00309\n",
            " ↪ x_angular_velocity_penalty: -1.523e-05\n",
            " ↪ x_naive_forward_reward: 0.001913\n",
            " ↪ y_angular_velocity_penalty: -2.908e-05\n",
            " ↪ y_linear_velocity_penalty: -7.515e-07\n",
            " ↪ z_angular_velocity_penalty: -4.055e-05\n",
            " ↪ z_linear_velocity_penalty: -1.631e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05638\n",
            " ↪ dt: 17.23\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m15\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,536,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m6m, 40s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001381\n",
            " ↪ action_smoothness_penalty: -4.507e-05\n",
            " ↪ actuator_jerk_penalty: -5.664e-06\n",
            " ↪ actuator_relative_force_penalty: -5.163e-06\n",
            " ↪ bent_arm_penalty: -2.459e-05\n",
            " ↪ stay_alive_reward: 0.001534\n",
            " ↪ total: 0.006491\n",
            " ↪ upright_reward: 0.003092\n",
            " ↪ x_angular_velocity_penalty: -1.518e-05\n",
            " ↪ x_naive_forward_reward: 0.001894\n",
            " ↪ y_angular_velocity_penalty: -2.814e-05\n",
            " ↪ y_linear_velocity_penalty: -7.718e-07\n",
            " ↪ z_angular_velocity_penalty: -4.062e-05\n",
            " ↪ z_linear_velocity_penalty: -1.57e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05625\n",
            " ↪ dt: 18.3\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m16\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,638,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m6m, 57s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001387\n",
            " ↪ action_smoothness_penalty: -4.469e-05\n",
            " ↪ actuator_jerk_penalty: -5.595e-06\n",
            " ↪ actuator_relative_force_penalty: -5.154e-06\n",
            " ↪ bent_arm_penalty: -2.445e-05\n",
            " ↪ stay_alive_reward: 0.001555\n",
            " ↪ total: 0.006456\n",
            " ↪ upright_reward: 0.003098\n",
            " ↪ x_angular_velocity_penalty: -1.496e-05\n",
            " ↪ x_naive_forward_reward: 0.001829\n",
            " ↪ y_angular_velocity_penalty: -2.691e-05\n",
            " ↪ y_linear_velocity_penalty: -7.851e-07\n",
            " ↪ z_angular_velocity_penalty: -4.013e-05\n",
            " ↪ z_linear_velocity_penalty: -1.5e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05635\n",
            " ↪ dt: 17.3\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m17\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,740,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m7m, 15s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001402\n",
            " ↪ action_smoothness_penalty: -4.427e-05\n",
            " ↪ actuator_jerk_penalty: -5.534e-06\n",
            " ↪ actuator_relative_force_penalty: -5.142e-06\n",
            " ↪ bent_arm_penalty: -2.46e-05\n",
            " ↪ stay_alive_reward: 0.001554\n",
            " ↪ total: 0.006422\n",
            " ↪ upright_reward: 0.003103\n",
            " ↪ x_angular_velocity_penalty: -1.462e-05\n",
            " ↪ x_naive_forward_reward: 0.001787\n",
            " ↪ y_angular_velocity_penalty: -2.649e-05\n",
            " ↪ y_linear_velocity_penalty: -7.806e-07\n",
            " ↪ z_angular_velocity_penalty: -3.991e-05\n",
            " ↪ z_linear_velocity_penalty: -1.445e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05644\n",
            " ↪ dt: 17.29\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.17.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:23:08\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.17.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m18\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,843,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m7m, 32s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001411\n",
            " ↪ action_smoothness_penalty: -4.392e-05\n",
            " ↪ actuator_jerk_penalty: -5.477e-06\n",
            " ↪ actuator_relative_force_penalty: -5.135e-06\n",
            " ↪ bent_arm_penalty: -2.461e-05\n",
            " ↪ stay_alive_reward: 0.001565\n",
            " ↪ total: 0.006556\n",
            " ↪ upright_reward: 0.00311\n",
            " ↪ x_angular_velocity_penalty: -1.458e-05\n",
            " ↪ x_naive_forward_reward: 0.001904\n",
            " ↪ y_angular_velocity_penalty: -2.647e-05\n",
            " ↪ y_linear_velocity_penalty: -7.788e-07\n",
            " ↪ z_angular_velocity_penalty: -4.034e-05\n",
            " ↪ z_linear_velocity_penalty: -1.443e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05653\n",
            " ↪ dt: 17.27\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m19\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,945,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m7m, 50s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001413\n",
            " ↪ action_smoothness_penalty: -4.363e-05\n",
            " ↪ actuator_jerk_penalty: -5.439e-06\n",
            " ↪ actuator_relative_force_penalty: -5.114e-06\n",
            " ↪ bent_arm_penalty: -2.464e-05\n",
            " ↪ stay_alive_reward: 0.001566\n",
            " ↪ total: 0.006661\n",
            " ↪ upright_reward: 0.00311\n",
            " ↪ x_angular_velocity_penalty: -1.448e-05\n",
            " ↪ x_naive_forward_reward: 0.002005\n",
            " ↪ y_angular_velocity_penalty: -2.639e-05\n",
            " ↪ y_linear_velocity_penalty: -7.643e-07\n",
            " ↪ z_angular_velocity_penalty: -3.989e-05\n",
            " ↪ z_linear_velocity_penalty: -1.417e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05648\n",
            " ↪ dt: 17.98\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;33mvalid\u001b[0m\n",
            " ↪ Steps: \u001b[36m19\u001b[0m\n",
            " ↪ Samples: \u001b[36m1,945,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m8m, 7s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001417\n",
            " ↪ action_smoothness_penalty: -4.356e-05\n",
            " ↪ actuator_jerk_penalty: -5.416e-06\n",
            " ↪ actuator_relative_force_penalty: -5.112e-06\n",
            " ↪ bent_arm_penalty: -2.469e-05\n",
            " ↪ stay_alive_reward: 0.001574\n",
            " ↪ total: 0.006605\n",
            " ↪ upright_reward: 0.003111\n",
            " ↪ x_angular_velocity_penalty: -1.419e-05\n",
            " ↪ x_naive_forward_reward: 0.00194\n",
            " ↪ y_angular_velocity_penalty: -2.573e-05\n",
            " ↪ y_linear_velocity_penalty: -7.754e-07\n",
            " ↪ z_angular_velocity_penalty: -4.007e-05\n",
            " ↪ z_linear_velocity_penalty: -1.395e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.01118\n",
            " ↪ dt: 178.8\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m20\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,048,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m8m, 7s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001418\n",
            " ↪ action_smoothness_penalty: -4.331e-05\n",
            " ↪ actuator_jerk_penalty: -5.421e-06\n",
            " ↪ actuator_relative_force_penalty: -5.094e-06\n",
            " ↪ bent_arm_penalty: -2.455e-05\n",
            " ↪ stay_alive_reward: 0.001579\n",
            " ↪ total: 0.00664\n",
            " ↪ upright_reward: 0.003105\n",
            " ↪ x_angular_velocity_penalty: -1.392e-05\n",
            " ↪ x_naive_forward_reward: 0.001974\n",
            " ↪ y_angular_velocity_penalty: -2.592e-05\n",
            " ↪ y_linear_velocity_penalty: -8.131e-07\n",
            " ↪ z_angular_velocity_penalty: -3.995e-05\n",
            " ↪ z_linear_velocity_penalty: -1.39e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05329\n",
            " ↪ dt: 37.79\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m21\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,150,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m8m, 25s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001418\n",
            " ↪ action_smoothness_penalty: -4.327e-05\n",
            " ↪ actuator_jerk_penalty: -5.382e-06\n",
            " ↪ actuator_relative_force_penalty: -5.087e-06\n",
            " ↪ bent_arm_penalty: -2.472e-05\n",
            " ↪ stay_alive_reward: 0.001576\n",
            " ↪ total: 0.006655\n",
            " ↪ upright_reward: 0.003102\n",
            " ↪ x_angular_velocity_penalty: -1.397e-05\n",
            " ↪ x_naive_forward_reward: 0.001994\n",
            " ↪ y_angular_velocity_penalty: -2.528e-05\n",
            " ↪ y_linear_velocity_penalty: -8.323e-07\n",
            " ↪ z_angular_velocity_penalty: -4.003e-05\n",
            " ↪ z_linear_velocity_penalty: -1.387e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.0535\n",
            " ↪ dt: 17.35\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.21.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:24:38\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.21.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m22\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,252,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m8m, 42s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001412\n",
            " ↪ action_smoothness_penalty: -4.33e-05\n",
            " ↪ actuator_jerk_penalty: -5.386e-06\n",
            " ↪ actuator_relative_force_penalty: -5.09e-06\n",
            " ↪ bent_arm_penalty: -2.479e-05\n",
            " ↪ stay_alive_reward: 0.00159\n",
            " ↪ total: 0.006566\n",
            " ↪ upright_reward: 0.003104\n",
            " ↪ x_angular_velocity_penalty: -1.384e-05\n",
            " ↪ x_naive_forward_reward: 0.001891\n",
            " ↪ y_angular_velocity_penalty: -2.478e-05\n",
            " ↪ y_linear_velocity_penalty: -8.145e-07\n",
            " ↪ z_angular_velocity_penalty: -4.036e-05\n",
            " ↪ z_linear_velocity_penalty: -1.353e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05369\n",
            " ↪ dt: 17.3\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m23\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,355,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m9m, 0s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001421\n",
            " ↪ action_smoothness_penalty: -4.329e-05\n",
            " ↪ actuator_jerk_penalty: -5.333e-06\n",
            " ↪ actuator_relative_force_penalty: -5.081e-06\n",
            " ↪ bent_arm_penalty: -2.48e-05\n",
            " ↪ stay_alive_reward: 0.001583\n",
            " ↪ total: 0.006616\n",
            " ↪ upright_reward: 0.003107\n",
            " ↪ x_angular_velocity_penalty: -1.375e-05\n",
            " ↪ x_naive_forward_reward: 0.001943\n",
            " ↪ y_angular_velocity_penalty: -2.513e-05\n",
            " ↪ y_linear_velocity_penalty: -8.214e-07\n",
            " ↪ z_angular_velocity_penalty: -4.036e-05\n",
            " ↪ z_linear_velocity_penalty: -1.348e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05377\n",
            " ↪ dt: 18\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m24\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,457,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m9m, 17s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001414\n",
            " ↪ action_smoothness_penalty: -4.329e-05\n",
            " ↪ actuator_jerk_penalty: -5.346e-06\n",
            " ↪ actuator_relative_force_penalty: -5.079e-06\n",
            " ↪ bent_arm_penalty: -2.481e-05\n",
            " ↪ stay_alive_reward: 0.001591\n",
            " ↪ total: 0.006663\n",
            " ↪ upright_reward: 0.003114\n",
            " ↪ x_angular_velocity_penalty: -1.362e-05\n",
            " ↪ x_naive_forward_reward: 0.001976\n",
            " ↪ y_angular_velocity_penalty: -2.488e-05\n",
            " ↪ y_linear_velocity_penalty: -8.556e-07\n",
            " ↪ z_angular_velocity_penalty: -4.028e-05\n",
            " ↪ z_linear_velocity_penalty: -1.323e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05394\n",
            " ↪ dt: 17.26\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m25\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,560,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m9m, 34s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001418\n",
            " ↪ action_smoothness_penalty: -4.294e-05\n",
            " ↪ actuator_jerk_penalty: -5.318e-06\n",
            " ↪ actuator_relative_force_penalty: -5.071e-06\n",
            " ↪ bent_arm_penalty: -2.492e-05\n",
            " ↪ stay_alive_reward: 0.001597\n",
            " ↪ total: 0.006745\n",
            " ↪ upright_reward: 0.003121\n",
            " ↪ x_angular_velocity_penalty: -1.358e-05\n",
            " ↪ x_naive_forward_reward: 0.002045\n",
            " ↪ y_angular_velocity_penalty: -2.516e-05\n",
            " ↪ y_linear_velocity_penalty: -7.936e-07\n",
            " ↪ z_angular_velocity_penalty: -4.065e-05\n",
            " ↪ z_linear_velocity_penalty: -1.342e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05409\n",
            " ↪ dt: 17.26\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.25.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:25:48\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.25.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m26\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,662,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m9m, 52s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001431\n",
            " ↪ action_smoothness_penalty: -4.268e-05\n",
            " ↪ actuator_jerk_penalty: -5.251e-06\n",
            " ↪ actuator_relative_force_penalty: -5.053e-06\n",
            " ↪ bent_arm_penalty: -2.477e-05\n",
            " ↪ stay_alive_reward: 0.00158\n",
            " ↪ total: 0.006826\n",
            " ↪ upright_reward: 0.00312\n",
            " ↪ x_angular_velocity_penalty: -1.325e-05\n",
            " ↪ x_naive_forward_reward: 0.002141\n",
            " ↪ y_angular_velocity_penalty: -2.474e-05\n",
            " ↪ y_linear_velocity_penalty: -7.55e-07\n",
            " ↪ z_angular_velocity_penalty: -4.1e-05\n",
            " ↪ z_linear_velocity_penalty: -1.339e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05423\n",
            " ↪ dt: 17.29\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m27\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,764,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m10m, 10s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001425\n",
            " ↪ action_smoothness_penalty: -4.292e-05\n",
            " ↪ actuator_jerk_penalty: -5.265e-06\n",
            " ↪ actuator_relative_force_penalty: -5.059e-06\n",
            " ↪ bent_arm_penalty: -2.484e-05\n",
            " ↪ stay_alive_reward: 0.001586\n",
            " ↪ total: 0.006808\n",
            " ↪ upright_reward: 0.00312\n",
            " ↪ x_angular_velocity_penalty: -1.341e-05\n",
            " ↪ x_naive_forward_reward: 0.002119\n",
            " ↪ y_angular_velocity_penalty: -2.525e-05\n",
            " ↪ y_linear_velocity_penalty: -7.653e-07\n",
            " ↪ z_angular_velocity_penalty: -4.073e-05\n",
            " ↪ z_linear_velocity_penalty: -1.317e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05424\n",
            " ↪ dt: 18.39\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m28\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,867,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m10m, 27s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001427\n",
            " ↪ action_smoothness_penalty: -4.249e-05\n",
            " ↪ actuator_jerk_penalty: -5.203e-06\n",
            " ↪ actuator_relative_force_penalty: -5.05e-06\n",
            " ↪ bent_arm_penalty: -2.489e-05\n",
            " ↪ stay_alive_reward: 0.001596\n",
            " ↪ total: 0.006939\n",
            " ↪ upright_reward: 0.003118\n",
            " ↪ x_angular_velocity_penalty: -1.304e-05\n",
            " ↪ x_naive_forward_reward: 0.002241\n",
            " ↪ y_angular_velocity_penalty: -2.55e-05\n",
            " ↪ y_linear_velocity_penalty: -7.746e-07\n",
            " ↪ z_angular_velocity_penalty: -4.05e-05\n",
            " ↪ z_linear_velocity_penalty: -1.306e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05436\n",
            " ↪ dt: 17.28\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;33mvalid\u001b[0m\n",
            " ↪ Steps: \u001b[36m28\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,867,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m10m, 45s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001434\n",
            " ↪ action_smoothness_penalty: -4.252e-05\n",
            " ↪ actuator_jerk_penalty: -5.2e-06\n",
            " ↪ actuator_relative_force_penalty: -5.037e-06\n",
            " ↪ bent_arm_penalty: -2.495e-05\n",
            " ↪ stay_alive_reward: 0.00159\n",
            " ↪ total: 0.007011\n",
            " ↪ upright_reward: 0.003113\n",
            " ↪ x_angular_velocity_penalty: -1.295e-05\n",
            " ↪ x_naive_forward_reward: 0.002325\n",
            " ↪ y_angular_velocity_penalty: -2.534e-05\n",
            " ↪ y_linear_velocity_penalty: -7.949e-07\n",
            " ↪ z_angular_velocity_penalty: -4.147e-05\n",
            " ↪ z_linear_velocity_penalty: -1.306e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.008407\n",
            " ↪ dt: 178\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m29\u001b[0m\n",
            " ↪ Samples: \u001b[36m2,969,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m10m, 45s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001436\n",
            " ↪ action_smoothness_penalty: -4.244e-05\n",
            " ↪ actuator_jerk_penalty: -5.153e-06\n",
            " ↪ actuator_relative_force_penalty: -5.031e-06\n",
            " ↪ bent_arm_penalty: -2.505e-05\n",
            " ↪ stay_alive_reward: 0.001593\n",
            " ↪ total: 0.00702\n",
            " ↪ upright_reward: 0.003117\n",
            " ↪ x_angular_velocity_penalty: -1.283e-05\n",
            " ↪ x_naive_forward_reward: 0.002326\n",
            " ↪ y_angular_velocity_penalty: -2.507e-05\n",
            " ↪ y_linear_velocity_penalty: -8.659e-07\n",
            " ↪ z_angular_velocity_penalty: -4.151e-05\n",
            " ↪ z_linear_velocity_penalty: -1.297e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05239\n",
            " ↪ dt: 37.8\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.29.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:27:19\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.29.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m30\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,072,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m11m, 2s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.000144\n",
            " ↪ action_smoothness_penalty: -4.228e-05\n",
            " ↪ actuator_jerk_penalty: -5.148e-06\n",
            " ↪ actuator_relative_force_penalty: -5.02e-06\n",
            " ↪ bent_arm_penalty: -2.503e-05\n",
            " ↪ stay_alive_reward: 0.001585\n",
            " ↪ total: 0.007067\n",
            " ↪ upright_reward: 0.003117\n",
            " ↪ x_angular_velocity_penalty: -1.277e-05\n",
            " ↪ x_naive_forward_reward: 0.00238\n",
            " ↪ y_angular_velocity_penalty: -2.474e-05\n",
            " ↪ y_linear_velocity_penalty: -8.659e-07\n",
            " ↪ z_angular_velocity_penalty: -4.197e-05\n",
            " ↪ z_linear_velocity_penalty: -1.316e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05255\n",
            " ↪ dt: 17.37\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m31\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,174,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m11m, 20s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001443\n",
            " ↪ action_smoothness_penalty: -4.223e-05\n",
            " ↪ actuator_jerk_penalty: -5.133e-06\n",
            " ↪ actuator_relative_force_penalty: -5.026e-06\n",
            " ↪ bent_arm_penalty: -2.505e-05\n",
            " ↪ stay_alive_reward: 0.001609\n",
            " ↪ total: 0.00703\n",
            " ↪ upright_reward: 0.00313\n",
            " ↪ x_angular_velocity_penalty: -1.286e-05\n",
            " ↪ x_naive_forward_reward: 0.002306\n",
            " ↪ y_angular_velocity_penalty: -2.394e-05\n",
            " ↪ y_linear_velocity_penalty: -8.541e-07\n",
            " ↪ z_angular_velocity_penalty: -4.15e-05\n",
            " ↪ z_linear_velocity_penalty: -1.276e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05264\n",
            " ↪ dt: 18.05\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m32\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,276,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m11m, 38s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001441\n",
            " ↪ action_smoothness_penalty: -4.198e-05\n",
            " ↪ actuator_jerk_penalty: -5.11e-06\n",
            " ↪ actuator_relative_force_penalty: -5.015e-06\n",
            " ↪ bent_arm_penalty: -2.518e-05\n",
            " ↪ stay_alive_reward: 0.001605\n",
            " ↪ total: 0.007067\n",
            " ↪ upright_reward: 0.003129\n",
            " ↪ x_angular_velocity_penalty: -1.254e-05\n",
            " ↪ x_naive_forward_reward: 0.002348\n",
            " ↪ y_angular_velocity_penalty: -2.417e-05\n",
            " ↪ y_linear_velocity_penalty: -8.795e-07\n",
            " ↪ z_angular_velocity_penalty: -4.225e-05\n",
            " ↪ z_linear_velocity_penalty: -1.279e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05279\n",
            " ↪ dt: 17.31\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m33\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,379,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m11m, 55s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001444\n",
            " ↪ action_smoothness_penalty: -4.172e-05\n",
            " ↪ actuator_jerk_penalty: -5.089e-06\n",
            " ↪ actuator_relative_force_penalty: -5.005e-06\n",
            " ↪ bent_arm_penalty: -2.494e-05\n",
            " ↪ stay_alive_reward: 0.001599\n",
            " ↪ total: 0.007101\n",
            " ↪ upright_reward: 0.003131\n",
            " ↪ x_angular_velocity_penalty: -1.23e-05\n",
            " ↪ x_naive_forward_reward: 0.002384\n",
            " ↪ y_angular_velocity_penalty: -2.398e-05\n",
            " ↪ y_linear_velocity_penalty: -8.464e-07\n",
            " ↪ z_angular_velocity_penalty: -4.202e-05\n",
            " ↪ z_linear_velocity_penalty: -1.279e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05294\n",
            " ↪ dt: 17.25\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.33.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:28:29\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.33.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m34\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,481,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m12m, 12s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001458\n",
            " ↪ action_smoothness_penalty: -4.153e-05\n",
            " ↪ actuator_jerk_penalty: -5.04e-06\n",
            " ↪ actuator_relative_force_penalty: -5.013e-06\n",
            " ↪ bent_arm_penalty: -2.492e-05\n",
            " ↪ stay_alive_reward: 0.001606\n",
            " ↪ total: 0.007104\n",
            " ↪ upright_reward: 0.003139\n",
            " ↪ x_angular_velocity_penalty: -1.233e-05\n",
            " ↪ x_naive_forward_reward: 0.00237\n",
            " ↪ y_angular_velocity_penalty: -2.359e-05\n",
            " ↪ y_linear_velocity_penalty: -8.454e-07\n",
            " ↪ z_angular_velocity_penalty: -4.191e-05\n",
            " ↪ z_linear_velocity_penalty: -1.266e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05308\n",
            " ↪ dt: 17.27\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m35\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,584,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m12m, 30s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001474\n",
            " ↪ action_smoothness_penalty: -4.129e-05\n",
            " ↪ actuator_jerk_penalty: -5.017e-06\n",
            " ↪ actuator_relative_force_penalty: -5.01e-06\n",
            " ↪ bent_arm_penalty: -2.5e-05\n",
            " ↪ stay_alive_reward: 0.001613\n",
            " ↪ total: 0.007155\n",
            " ↪ upright_reward: 0.00314\n",
            " ↪ x_angular_velocity_penalty: -1.223e-05\n",
            " ↪ x_naive_forward_reward: 0.002411\n",
            " ↪ y_angular_velocity_penalty: -2.353e-05\n",
            " ↪ y_linear_velocity_penalty: -8.791e-07\n",
            " ↪ z_angular_velocity_penalty: -4.221e-05\n",
            " ↪ z_linear_velocity_penalty: -1.252e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05315\n",
            " ↪ dt: 18.01\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m36\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,686,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m12m, 47s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001489\n",
            " ↪ action_smoothness_penalty: -4.092e-05\n",
            " ↪ actuator_jerk_penalty: -4.99e-06\n",
            " ↪ actuator_relative_force_penalty: -5.005e-06\n",
            " ↪ bent_arm_penalty: -2.496e-05\n",
            " ↪ stay_alive_reward: 0.001613\n",
            " ↪ total: 0.007164\n",
            " ↪ upright_reward: 0.003144\n",
            " ↪ x_angular_velocity_penalty: -1.204e-05\n",
            " ↪ x_naive_forward_reward: 0.002413\n",
            " ↪ y_angular_velocity_penalty: -2.316e-05\n",
            " ↪ y_linear_velocity_penalty: -8.85e-07\n",
            " ↪ z_angular_velocity_penalty: -4.213e-05\n",
            " ↪ z_linear_velocity_penalty: -1.263e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05327\n",
            " ↪ dt: 17.28\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m37\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,788,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m13m, 5s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001499\n",
            " ↪ action_smoothness_penalty: -4.049e-05\n",
            " ↪ actuator_jerk_penalty: -4.953e-06\n",
            " ↪ actuator_relative_force_penalty: -4.981e-06\n",
            " ↪ bent_arm_penalty: -2.487e-05\n",
            " ↪ stay_alive_reward: 0.001613\n",
            " ↪ total: 0.007203\n",
            " ↪ upright_reward: 0.003146\n",
            " ↪ x_angular_velocity_penalty: -1.195e-05\n",
            " ↪ x_naive_forward_reward: 0.002449\n",
            " ↪ y_angular_velocity_penalty: -2.289e-05\n",
            " ↪ y_linear_velocity_penalty: -8.648e-07\n",
            " ↪ z_angular_velocity_penalty: -4.212e-05\n",
            " ↪ z_linear_velocity_penalty: -1.241e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05339\n",
            " ↪ dt: 17.28\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.37.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:29:38\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.37.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;33mvalid\u001b[0m\n",
            " ↪ Steps: \u001b[36m37\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,788,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m13m, 22s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001499\n",
            " ↪ action_smoothness_penalty: -4.062e-05\n",
            " ↪ actuator_jerk_penalty: -4.946e-06\n",
            " ↪ actuator_relative_force_penalty: -4.979e-06\n",
            " ↪ bent_arm_penalty: -2.488e-05\n",
            " ↪ stay_alive_reward: 0.001621\n",
            " ↪ total: 0.007206\n",
            " ↪ upright_reward: 0.003147\n",
            " ↪ x_angular_velocity_penalty: -1.197e-05\n",
            " ↪ x_naive_forward_reward: 0.002444\n",
            " ↪ y_angular_velocity_penalty: -2.292e-05\n",
            " ↪ y_linear_velocity_penalty: -8.872e-07\n",
            " ↪ z_angular_velocity_penalty: -4.281e-05\n",
            " ↪ z_linear_velocity_penalty: -1.219e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.007486\n",
            " ↪ dt: 177.5\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m38\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,891,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m13m, 22s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001509\n",
            " ↪ action_smoothness_penalty: -4.024e-05\n",
            " ↪ actuator_jerk_penalty: -4.895e-06\n",
            " ↪ actuator_relative_force_penalty: -4.968e-06\n",
            " ↪ bent_arm_penalty: -2.486e-05\n",
            " ↪ stay_alive_reward: 0.001625\n",
            " ↪ total: 0.007184\n",
            " ↪ upright_reward: 0.003153\n",
            " ↪ x_angular_velocity_penalty: -1.176e-05\n",
            " ↪ x_naive_forward_reward: 0.002408\n",
            " ↪ y_angular_velocity_penalty: -2.24e-05\n",
            " ↪ y_linear_velocity_penalty: -9.064e-07\n",
            " ↪ z_angular_velocity_penalty: -4.137e-05\n",
            " ↪ z_linear_velocity_penalty: -1.19e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05191\n",
            " ↪ dt: 38.5\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m39\u001b[0m\n",
            " ↪ Samples: \u001b[36m3,993,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m13m, 39s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001517\n",
            " ↪ action_smoothness_penalty: -4.01e-05\n",
            " ↪ actuator_jerk_penalty: -4.839e-06\n",
            " ↪ actuator_relative_force_penalty: -4.975e-06\n",
            " ↪ bent_arm_penalty: -2.483e-05\n",
            " ↪ stay_alive_reward: 0.001632\n",
            " ↪ total: 0.007151\n",
            " ↪ upright_reward: 0.003159\n",
            " ↪ x_angular_velocity_penalty: -1.178e-05\n",
            " ↪ x_naive_forward_reward: 0.002361\n",
            " ↪ y_angular_velocity_penalty: -2.227e-05\n",
            " ↪ y_linear_velocity_penalty: -8.765e-07\n",
            " ↪ z_angular_velocity_penalty: -4.145e-05\n",
            " ↪ z_linear_velocity_penalty: -1.184e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05205\n",
            " ↪ dt: 17.35\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m40\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,096,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m13m, 56s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001508\n",
            " ↪ action_smoothness_penalty: -4.029e-05\n",
            " ↪ actuator_jerk_penalty: -4.831e-06\n",
            " ↪ actuator_relative_force_penalty: -4.978e-06\n",
            " ↪ bent_arm_penalty: -2.494e-05\n",
            " ↪ stay_alive_reward: 0.001636\n",
            " ↪ total: 0.007178\n",
            " ↪ upright_reward: 0.003159\n",
            " ↪ x_angular_velocity_penalty: -1.19e-05\n",
            " ↪ x_naive_forward_reward: 0.002386\n",
            " ↪ y_angular_velocity_penalty: -2.212e-05\n",
            " ↪ y_linear_velocity_penalty: -8.81e-07\n",
            " ↪ z_angular_velocity_penalty: -4.287e-05\n",
            " ↪ z_linear_velocity_penalty: -1.151e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05218\n",
            " ↪ dt: 17.28\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m41\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,198,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m14m, 14s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.000152\n",
            " ↪ action_smoothness_penalty: -3.976e-05\n",
            " ↪ actuator_jerk_penalty: -4.795e-06\n",
            " ↪ actuator_relative_force_penalty: -4.958e-06\n",
            " ↪ bent_arm_penalty: -2.495e-05\n",
            " ↪ stay_alive_reward: 0.001632\n",
            " ↪ total: 0.007145\n",
            " ↪ upright_reward: 0.00316\n",
            " ↪ x_angular_velocity_penalty: -1.166e-05\n",
            " ↪ x_naive_forward_reward: 0.002354\n",
            " ↪ y_angular_velocity_penalty: -2.158e-05\n",
            " ↪ y_linear_velocity_penalty: -9.498e-07\n",
            " ↪ z_angular_velocity_penalty: -4.206e-05\n",
            " ↪ z_linear_velocity_penalty: -1.154e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05231\n",
            " ↪ dt: 17.25\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.41.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:31:09\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.41.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m42\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,300,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m14m, 31s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001509\n",
            " ↪ action_smoothness_penalty: -3.991e-05\n",
            " ↪ actuator_jerk_penalty: -4.799e-06\n",
            " ↪ actuator_relative_force_penalty: -4.96e-06\n",
            " ↪ bent_arm_penalty: -2.501e-05\n",
            " ↪ stay_alive_reward: 0.00164\n",
            " ↪ total: 0.007185\n",
            " ↪ upright_reward: 0.003158\n",
            " ↪ x_angular_velocity_penalty: -1.159e-05\n",
            " ↪ x_naive_forward_reward: 0.002388\n",
            " ↪ y_angular_velocity_penalty: -2.243e-05\n",
            " ↪ y_linear_velocity_penalty: -9.811e-07\n",
            " ↪ z_angular_velocity_penalty: -4.198e-05\n",
            " ↪ z_linear_velocity_penalty: -1.146e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05244\n",
            " ↪ dt: 17.25\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m43\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,403,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m14m, 49s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.000152\n",
            " ↪ action_smoothness_penalty: -3.971e-05\n",
            " ↪ actuator_jerk_penalty: -4.776e-06\n",
            " ↪ actuator_relative_force_penalty: -4.954e-06\n",
            " ↪ bent_arm_penalty: -2.494e-05\n",
            " ↪ stay_alive_reward: 0.00164\n",
            " ↪ total: 0.007244\n",
            " ↪ upright_reward: 0.00316\n",
            " ↪ x_angular_velocity_penalty: -1.154e-05\n",
            " ↪ x_naive_forward_reward: 0.002445\n",
            " ↪ y_angular_velocity_penalty: -2.199e-05\n",
            " ↪ y_linear_velocity_penalty: -9.592e-07\n",
            " ↪ z_angular_velocity_penalty: -4.235e-05\n",
            " ↪ z_linear_velocity_penalty: -1.128e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.0525\n",
            " ↪ dt: 18.03\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m44\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,505,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m15m, 6s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001524\n",
            " ↪ action_smoothness_penalty: -3.934e-05\n",
            " ↪ actuator_jerk_penalty: -4.697e-06\n",
            " ↪ actuator_relative_force_penalty: -4.945e-06\n",
            " ↪ bent_arm_penalty: -2.486e-05\n",
            " ↪ stay_alive_reward: 0.001644\n",
            " ↪ total: 0.007296\n",
            " ↪ upright_reward: 0.003162\n",
            " ↪ x_angular_velocity_penalty: -1.133e-05\n",
            " ↪ x_naive_forward_reward: 0.00249\n",
            " ↪ y_angular_velocity_penalty: -2.195e-05\n",
            " ↪ y_linear_velocity_penalty: -1.014e-06\n",
            " ↪ z_angular_velocity_penalty: -4.324e-05\n",
            " ↪ z_linear_velocity_penalty: -1.102e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05261\n",
            " ↪ dt: 17.37\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m45\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,608,000\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m15m, 24s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001533\n",
            " ↪ action_smoothness_penalty: -3.941e-05\n",
            " ↪ actuator_jerk_penalty: -4.759e-06\n",
            " ↪ actuator_relative_force_penalty: -4.941e-06\n",
            " ↪ bent_arm_penalty: -2.483e-05\n",
            " ↪ stay_alive_reward: 0.001636\n",
            " ↪ total: 0.007259\n",
            " ↪ upright_reward: 0.003161\n",
            " ↪ x_angular_velocity_penalty: -1.163e-05\n",
            " ↪ x_naive_forward_reward: 0.002462\n",
            " ↪ y_angular_velocity_penalty: -2.225e-05\n",
            " ↪ y_linear_velocity_penalty: -1.023e-06\n",
            " ↪ z_angular_velocity_penalty: -4.356e-05\n",
            " ↪ z_linear_velocity_penalty: -1.146e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05272\n",
            " ↪ dt: 17.27\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:xax.task.mixins.checkpointing:Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.45.bin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  \u001b[1;36mINFO\u001b[0m  \u001b[90m2025-05-02 22:32:19\u001b[0m [\u001b[1;34mxax.task.mixins.checkpointing\u001b[0m] Saving checkpoint to /content/humanoid_walking_task/run_0/checkpoints/ckpt.45.bin\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m46\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,710,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m15m, 41s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001538\n",
            " ↪ action_smoothness_penalty: -3.929e-05\n",
            " ↪ actuator_jerk_penalty: -4.691e-06\n",
            " ↪ actuator_relative_force_penalty: -4.942e-06\n",
            " ↪ bent_arm_penalty: -2.48e-05\n",
            " ↪ stay_alive_reward: 0.001641\n",
            " ↪ total: 0.007247\n",
            " ↪ upright_reward: 0.003161\n",
            " ↪ x_angular_velocity_penalty: -1.144e-05\n",
            " ↪ x_naive_forward_reward: 0.002445\n",
            " ↪ y_angular_velocity_penalty: -2.186e-05\n",
            " ↪ y_linear_velocity_penalty: -1.079e-06\n",
            " ↪ z_angular_velocity_penalty: -4.377e-05\n",
            " ↪ z_linear_velocity_penalty: -1.123e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05282\n",
            " ↪ dt: 17.35\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;33mvalid\u001b[0m\n",
            " ↪ Steps: \u001b[36m46\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,710,400\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m15m, 59s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001535\n",
            " ↪ action_smoothness_penalty: -3.921e-05\n",
            " ↪ actuator_jerk_penalty: -4.697e-06\n",
            " ↪ actuator_relative_force_penalty: -4.941e-06\n",
            " ↪ bent_arm_penalty: -2.481e-05\n",
            " ↪ stay_alive_reward: 0.001649\n",
            " ↪ total: 0.007273\n",
            " ↪ upright_reward: 0.003162\n",
            " ↪ x_angular_velocity_penalty: -1.153e-05\n",
            " ↪ x_naive_forward_reward: 0.002461\n",
            " ↪ y_angular_velocity_penalty: -2.165e-05\n",
            " ↪ y_linear_velocity_penalty: -1.043e-06\n",
            " ↪ z_angular_velocity_penalty: -4.363e-05\n",
            " ↪ z_linear_velocity_penalty: -1.109e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.007015\n",
            " ↪ dt: 178.4\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m47\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,812,800\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m15m, 59s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001525\n",
            " ↪ action_smoothness_penalty: -3.919e-05\n",
            " ↪ actuator_jerk_penalty: -4.648e-06\n",
            " ↪ actuator_relative_force_penalty: -4.935e-06\n",
            " ↪ bent_arm_penalty: -2.48e-05\n",
            " ↪ stay_alive_reward: 0.001655\n",
            " ↪ total: 0.007344\n",
            " ↪ upright_reward: 0.003164\n",
            " ↪ x_angular_velocity_penalty: -1.159e-05\n",
            " ↪ x_naive_forward_reward: 0.002525\n",
            " ↪ y_angular_velocity_penalty: -2.147e-05\n",
            " ↪ y_linear_velocity_penalty: -1.117e-06\n",
            " ↪ z_angular_velocity_penalty: -4.384e-05\n",
            " ↪ z_linear_velocity_penalty: -1.105e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.0516\n",
            " ↪ dt: 39.49\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m48\u001b[0m\n",
            " ↪ Samples: \u001b[36m4,915,200\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m16m, 16s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.0001542\n",
            " ↪ action_smoothness_penalty: -3.906e-05\n",
            " ↪ actuator_jerk_penalty: -4.696e-06\n",
            " ↪ actuator_relative_force_penalty: -4.936e-06\n",
            " ↪ bent_arm_penalty: -2.486e-05\n",
            " ↪ stay_alive_reward: 0.001641\n",
            " ↪ total: 0.007352\n",
            " ↪ upright_reward: 0.00316\n",
            " ↪ x_angular_velocity_penalty: -1.156e-05\n",
            " ↪ x_naive_forward_reward: 0.002551\n",
            " ↪ y_angular_velocity_penalty: -2.178e-05\n",
            " ↪ y_linear_velocity_penalty: -1.13e-06\n",
            " ↪ z_angular_velocity_penalty: -4.483e-05\n",
            " ↪ z_linear_velocity_penalty: -1.135e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05172\n",
            " ↪ dt: 17.33\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n",
            "\u001b[2J\u001b[H\u001b[1;90mPhase: \u001b[0m\u001b[1;32mtrain\u001b[0m\n",
            " ↪ Steps: \u001b[36m49\u001b[0m\n",
            " ↪ Samples: \u001b[36m5,017,600\u001b[0m\n",
            " ↪ Elapsed Time: \u001b[36m16m, 34s\u001b[0m\n",
            "\n",
            "\u001b[1;36m🎁 reward\u001b[0m\n",
            " ↪ action_in_bounds_reward: 0.000154\n",
            " ↪ action_smoothness_penalty: -3.906e-05\n",
            " ↪ actuator_jerk_penalty: -4.667e-06\n",
            " ↪ actuator_relative_force_penalty: -4.93e-06\n",
            " ↪ bent_arm_penalty: -2.489e-05\n",
            " ↪ stay_alive_reward: 0.001652\n",
            " ↪ total: 0.00732\n",
            " ↪ upright_reward: 0.003162\n",
            " ↪ x_angular_velocity_penalty: -1.157e-05\n",
            " ↪ x_naive_forward_reward: 0.002504\n",
            " ↪ y_angular_velocity_penalty: -2.144e-05\n",
            " ↪ y_linear_velocity_penalty: -1.14e-06\n",
            " ↪ z_angular_velocity_penalty: -4.332e-05\n",
            " ↪ z_linear_velocity_penalty: -1.121e-06\n",
            "\n",
            "\u001b[1;36m🕒 timers\u001b[0m\n",
            " ↪ steps/second: 0.05183\n",
            " ↪ dt: 17.37\n",
            "\n",
            "\u001b[1;90mStatus\u001b[0m\n",
            " ✦ \u001b[32mTensorboard: http://3521daa4530a:6036/\u001b[0m\n",
            " ✦ \u001b[32mFirst step time: 2m, 53s\u001b[0m\n",
            " ✦ \u001b[32mJAX devices: [CudaDevice(id=0)]\u001b[0m\n",
            " ✦ \u001b[32mhumanoid_walking_task\u001b[0m\n",
            " ✦ \u001b[32m/content\u001b[0m\n",
            " ✦ \u001b[32m/content/humanoid_walking_task/run_0\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "HumanoidWalkingTask.launch(\n",
        "    HumanoidWalkingTaskConfig(\n",
        "        # Training parameters.\n",
        "        num_envs=2048,\n",
        "        batch_size=128,\n",
        "        num_passes=2,\n",
        "        epochs_per_log_step=1,\n",
        "        rollout_length_seconds=1.0,\n",
        "        # Simulation parameters.\n",
        "        dt=0.002,\n",
        "        ctrl_dt=0.02,\n",
        "        iterations=8,\n",
        "        ls_iterations=8,\n",
        "        max_action_latency=0.01,\n",
        "        # Checkpointing parameters.\n",
        "        save_every_n_seconds=60,\n",
        "        # Xax parameters.\n",
        "        disable_multiprocessing=True,\n",
        "    ),\n",
        "    use_cli=False,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
